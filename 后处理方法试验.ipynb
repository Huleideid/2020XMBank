{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 后处理方法试验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "K5fIv3ugNq1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aum_m10.csv\n",
      "aum_m11.csv\n",
      "aum_m12.csv\n",
      "aum_m7.csv\n",
      "aum_m8.csv\n",
      "aum_m9.csv\n",
      "aum_m1.csv\n",
      "aum_m2.csv\n",
      "aum_m3.csv\n",
      "behavior_m10.csv\n",
      "behavior_m11.csv\n",
      "behavior_m12.csv\n",
      "behavior_m7.csv\n",
      "behavior_m8.csv\n",
      "behavior_m9.csv\n",
      "behavior_m1.csv\n",
      "behavior_m2.csv\n",
      "behavior_m3.csv\n",
      "big_event_Q3.csv\n",
      "big_event_Q4.csv\n",
      "big_event_Q1.csv\n",
      "cunkuan_m10.csv\n",
      "cunkuan_m11.csv\n",
      "cunkuan_m12.csv\n",
      "cunkuan_m7.csv\n",
      "cunkuan_m8.csv\n",
      "cunkuan_m9.csv\n",
      "cunkuan_m1.csv\n",
      "cunkuan_m2.csv\n",
      "cunkuan_m3.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "from sklearn.metrics import cohen_kappa_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "os.getcwd() \n",
    "os.chdir('./data')\n",
    "\n",
    "\n",
    "### 读取数据\n",
    "y_Q3_3 = pd.read_csv('./y_train_3/y_Q3_3.csv')\n",
    "y_Q4_3 = pd.read_csv('./y_train_3/y_Q4_3.csv')\n",
    "\n",
    "aum_fils = os.listdir('x_train/aum_train/')+os.listdir('x_test/aum_test/')\n",
    "aum = []\n",
    "for f in aum_fils:\n",
    "    print(f)\n",
    "    mon = int((f.split('.')[0]).split('_')[-1].replace('m', ''))\n",
    "    if mon>=7:\n",
    "        tmp = pd.read_csv('x_train/aum_train/'+f)\n",
    "        tmp['mon'] = mon\n",
    "    else:\n",
    "        tmp = pd.read_csv('x_test/aum_test/'+f)\n",
    "        tmp['mon'] = mon+12\n",
    "    aum.append(tmp)\n",
    "aum = pd.concat(aum, axis=0, ignore_index=True)\n",
    "\n",
    "behavior_fils = os.listdir('x_train/behavior_train/')+os.listdir('x_test/behavior_test/')\n",
    "behavior = []\n",
    "for f in behavior_fils:\n",
    "    print(f)\n",
    "    mon = int((f.split('.')[0]).split('_')[-1].replace('m', ''))\n",
    "    if mon>=7:\n",
    "        tmp = pd.read_csv('x_train/behavior_train/'+f)\n",
    "        tmp['mon'] = mon\n",
    "    else:\n",
    "        tmp = pd.read_csv('x_test/behavior_test/'+f)\n",
    "        tmp['mon'] = mon+12\n",
    "    behavior.append(tmp)\n",
    "behavior = pd.concat(behavior, axis=0, ignore_index=True)\n",
    "\n",
    "event_fils = os.listdir('x_train/big_event_train/')+os.listdir('x_test/big_event_test/')\n",
    "event = []\n",
    "for f in event_fils:\n",
    "    print(f)\n",
    "    season = int((f.split('.')[0]).split('_')[-1].replace('Q', ''))\n",
    "    if season>=3:\n",
    "        tmp = pd.read_csv('x_train/big_event_train/'+f)\n",
    "        tmp['season'] = season\n",
    "    else:\n",
    "        tmp = pd.read_csv('x_test/big_event_test/'+f)\n",
    "        tmp['season'] = season + 4\n",
    "    \n",
    "    event.append(tmp)\n",
    "event = pd.concat(event, axis=0, ignore_index=True)\n",
    "\n",
    "cunkuan_fils = os.listdir('x_train/cunkuan_train/')+os.listdir('x_test/cunkuan_test/')\n",
    "cunkuan = []\n",
    "for f in cunkuan_fils:\n",
    "    print(f)\n",
    "    mon = int((f.split('.')[0]).split('_')[-1].replace('m', ''))\n",
    "    if mon>=7:\n",
    "        tmp = pd.read_csv('x_train/cunkuan_train/'+f)\n",
    "        tmp['mon'] = mon\n",
    "    else:\n",
    "        tmp = pd.read_csv('x_test/cunkuan_test/'+f)\n",
    "        tmp['mon'] = mon+12\n",
    "    cunkuan.append(tmp)\n",
    "cunkuan = pd.concat(cunkuan, axis=0, ignore_index=True)\n",
    "\n",
    "cust_avli_Q3 = pd.read_csv('./x_train/cust_avli_Q3.csv')\n",
    "cust_avli_Q4 = pd.read_csv('./x_train/cust_avli_Q4.csv')\n",
    "cust_info_Q3 = pd.read_csv('x_train/cust_info_q3.csv')\n",
    "cust_info_Q4 = pd.read_csv('x_train/cust_info_q4.csv')\n",
    "cust_avli_Q1 = pd.read_csv('x_test/cust_avli_Q1.csv')\n",
    "cust_info_Q1 = pd.read_csv('x_test/cust_info_q1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征工程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0g4M4E5NNq1i"
   },
   "source": [
    "第一组特征很自然的想到用户历史的label，例如在预测季度4的用户时，使用用户在季度3的label作为特征。可以简单看到这个特征的kappa值可以达到0.238+。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_no</th>\n",
       "      <th>bef_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x3b9b4615</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x3b9ae61b</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x3b9add69</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x3b9b3601</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x3b9b2599</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76717</th>\n",
       "      <td>0xb2d69017</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76718</th>\n",
       "      <td>0xb2d68153</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76719</th>\n",
       "      <td>0xb2d5bba1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76720</th>\n",
       "      <td>0xb2d61b9b</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76721</th>\n",
       "      <td>0xb2d70079</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76722 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          cust_no  bef_label\n",
       "0      0x3b9b4615        0.0\n",
       "1      0x3b9ae61b        1.0\n",
       "2      0x3b9add69        0.0\n",
       "3      0x3b9b3601        0.0\n",
       "4      0x3b9b2599        0.0\n",
       "...           ...        ...\n",
       "76717  0xb2d69017        0.0\n",
       "76718  0xb2d68153        1.0\n",
       "76719  0xb2d5bba1        1.0\n",
       "76720  0xb2d61b9b        1.0\n",
       "76721  0xb2d70079        0.0\n",
       "\n",
       "[76722 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = y_Q4_3.copy()\n",
    "y_Q3_3 = y_Q3_3.rename(columns={'label': 'bef_label'})\n",
    "train = train.merge(y_Q3_3, on=['cust_no'], how='left').copy()\n",
    "\n",
    "test = cust_avli_Q1.copy()\n",
    "y_Q4_3 = y_Q4_3.rename(columns={'label': 'bef_label'})\n",
    "test = test.merge(y_Q4_3, on=['cust_no'], how='left')\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用户信息\n",
    "比较重要的是用户等级"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_no</th>\n",
       "      <th>bef_label</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3_x</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I10</th>\n",
       "      <th>I11</th>\n",
       "      <th>I13</th>\n",
       "      <th>I14</th>\n",
       "      <th>I16</th>\n",
       "      <th>I3_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x3b9b4615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>女性</td>\n",
       "      <td>27</td>\n",
       "      <td>黄金</td>\n",
       "      <td>0.0</td>\n",
       "      <td>服务性工作人员</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>黄金</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x3b9ae61b</td>\n",
       "      <td>1.0</td>\n",
       "      <td>女性</td>\n",
       "      <td>45</td>\n",
       "      <td>黄金</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>黄金</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x3b9add69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>男性</td>\n",
       "      <td>75</td>\n",
       "      <td>黄金</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>黄金</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x3b9b3601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>女性</td>\n",
       "      <td>49</td>\n",
       "      <td>黄金</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>黄金</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x3b9b2599</td>\n",
       "      <td>0.0</td>\n",
       "      <td>女性</td>\n",
       "      <td>60</td>\n",
       "      <td>黄金</td>\n",
       "      <td>0.0</td>\n",
       "      <td>不便分类的其他从业人员</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>黄金</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76717</th>\n",
       "      <td>0xb2d69017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>女性</td>\n",
       "      <td>19</td>\n",
       "      <td>普通客户</td>\n",
       "      <td>0.0</td>\n",
       "      <td>商业工作人员</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>普通客户</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76718</th>\n",
       "      <td>0xb2d68153</td>\n",
       "      <td>1.0</td>\n",
       "      <td>女性</td>\n",
       "      <td>67</td>\n",
       "      <td>黄金</td>\n",
       "      <td>0.0</td>\n",
       "      <td>服务性工作人员</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>黄金</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76719</th>\n",
       "      <td>0xb2d5bba1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>女性</td>\n",
       "      <td>59</td>\n",
       "      <td>白金</td>\n",
       "      <td>0.0</td>\n",
       "      <td>不便分类的其他从业人员</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>黄金</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76720</th>\n",
       "      <td>0xb2d61b9b</td>\n",
       "      <td>1.0</td>\n",
       "      <td>男性</td>\n",
       "      <td>73</td>\n",
       "      <td>普通客户</td>\n",
       "      <td>0.0</td>\n",
       "      <td>农、林、牧、渔、水利业生产人员</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>普通客户</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76721</th>\n",
       "      <td>0xb2d70079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>男性</td>\n",
       "      <td>45</td>\n",
       "      <td>普通客户</td>\n",
       "      <td>0.0</td>\n",
       "      <td>商业工作人员</td>\n",
       "      <td>1</td>\n",
       "      <td>专科教育</td>\n",
       "      <td>3399996.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>高级领导(行政级别局级及局级以上领导或大公司高级管理人员)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>普通客户</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76722 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          cust_no  bef_label  I1  I2  I3_x   I4               I5  I6   I10  \\\n",
       "0      0x3b9b4615        0.0  女性  27    黄金  0.0          服务性工作人员   0   NaN   \n",
       "1      0x3b9ae61b        1.0  女性  45    黄金  1.0              NaN   1   NaN   \n",
       "2      0x3b9add69        0.0  男性  75    黄金  0.0              NaN   0   NaN   \n",
       "3      0x3b9b3601        0.0  女性  49    黄金  0.0              NaN   0   NaN   \n",
       "4      0x3b9b2599        0.0  女性  60    黄金  0.0      不便分类的其他从业人员   0   NaN   \n",
       "...           ...        ...  ..  ..   ...  ...              ...  ..   ...   \n",
       "76717  0xb2d69017        0.0  女性  19  普通客户  0.0           商业工作人员   0   NaN   \n",
       "76718  0xb2d68153        1.0  女性  67    黄金  0.0          服务性工作人员   0   NaN   \n",
       "76719  0xb2d5bba1        1.0  女性  59    白金  0.0      不便分类的其他从业人员   0   NaN   \n",
       "76720  0xb2d61b9b        1.0  男性  73  普通客户  0.0  农、林、牧、渔、水利业生产人员   0   NaN   \n",
       "76721  0xb2d70079        0.0  男性  45  普通客户  0.0           商业工作人员   1  专科教育   \n",
       "\n",
       "             I11  I13                            I14  I16  I3_y  \n",
       "0            0.0  NaN                            NaN  1.0    黄金  \n",
       "1            0.0  NaN                            NaN  1.0    黄金  \n",
       "2            0.0  NaN                            NaN  1.0    黄金  \n",
       "3            0.0  NaN                            NaN  1.0    黄金  \n",
       "4            0.0  NaN                            NaN  1.0    黄金  \n",
       "...          ...  ...                            ...  ...   ...  \n",
       "76717        0.0  NaN                            NaN  0.0  普通客户  \n",
       "76718        0.0  NaN                            NaN  1.0    黄金  \n",
       "76719        0.0  NaN                            NaN  1.0    黄金  \n",
       "76720        0.0  NaN                            NaN  0.0  普通客户  \n",
       "76721  3399996.0  NaN  高级领导(行政级别局级及局级以上领导或大公司高级管理人员)  0.0  普通客户  \n",
       "\n",
       "[76722 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 根据EDA去掉一部分的列\n",
    "cust_info_Q4.drop(columns = ['I7','I8','I9','I12','I15','I17','I18','I19','I20'], inplace=True)\n",
    "cust_info_Q3.drop(columns = ['I7','I8','I9','I12','I15','I17','I18','I19','I20'], inplace=True)\n",
    "cust_info_Q1.drop(columns = ['I7','I8','I9','I12','I15','I17','I18','I19','I20'], inplace=True)\n",
    "train = train.merge(cust_info_Q4, on=['cust_no'], how='left')\n",
    "train = train.merge(cust_info_Q3[['cust_no','I3']], on=['cust_no'], how='left')\n",
    "test = test.merge(cust_info_Q1, on=['cust_no'], how='left')\n",
    "test = test.merge(cust_info_Q4[['cust_no','I3']], on=['cust_no'], how='left')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "g3eWrptrNq1i"
   },
   "outputs": [],
   "source": [
    "### 对年龄进行分箱\n",
    "def get_age(x):\n",
    "    if x<18:\n",
    "        return 1\n",
    "    elif x<30:\n",
    "        return 2\n",
    "    elif x<40:\n",
    "        return 3 \n",
    "    elif x<50:\n",
    "        return 4    \n",
    "    elif x<60:\n",
    "        return 5  \n",
    "    elif x<80:\n",
    "        return 6\n",
    "    else:\n",
    "        return 7  \n",
    "\n",
    "train['I2'] = train['I2'].apply(lambda x: get_age(x))\n",
    "test['I2'] = test['I2'].apply(lambda x: get_age(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I1\n",
      "I3_x\n",
      "I5\n",
      "I10\n",
      "I13\n",
      "I14\n",
      "I3_y\n"
     ]
    }
   ],
   "source": [
    "### 其他特征编码\n",
    "for col in [f for f in train.select_dtypes('object').columns if f not in ['label', 'cust_no']]:\n",
    "    print(col)\n",
    "    train[col].fillna(train[col].mode()[0], inplace=True)### 缺失值处理·\n",
    "    test[col].fillna(train[col].mode()[0], inplace=True)### 缺失值处理·\n",
    "    le = LabelEncoder()\n",
    "    le.fit(pd.concat([train[[col]], test[[col]]], axis=0, ignore_index=True))\n",
    "    train[col] = le.transform(train[col])\n",
    "    test[col] = le.transform(test[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用户行为特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sy_d3z-iNq1k"
   },
   "source": [
    "这题最重要的应该是用户行为相关的数据，下面我们开始做一些简单的操作：\n",
    "1. 用户当季度存款（cunkuan）的mean、max、min、std、sum、last的统计\n",
    "2. 用户当季度最后一个月的aum数据\n",
    "3. 用户当季度最后一个月的behavior数据\n",
    "4. 用户当季度的event的特征，这里大多数都是时间，所以用该季度月末的后一天做时间差特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征工程1\n",
    "#### 1. 用户当季度存款(cunkuan)的mean、max、min、std、sum、last、skew、kurtosis的统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_correlated_col(df, cutoff):\n",
    "    # 筛选高度相关特征\n",
    "    def filter_corr(corr, cutoff=0.9):\n",
    "        cols = []\n",
    "        for i,j in feature_group:\n",
    "            if corr.loc[i, j] > cutoff:\n",
    "                print(i,j,corr.loc[i, j])\n",
    "                i_avg = corr[i][corr[i] != 1].mean()\n",
    "                j_avg = corr[j][corr[j] != 1].mean()\n",
    "                if i_avg >= j_avg:\n",
    "                    cols.append(i)\n",
    "                else:\n",
    "                    cols.append(j)\n",
    "        return set(cols)\n",
    "\n",
    "    corr = df.corr()\n",
    "    feature_group = list(itertools.combinations(corr.columns, 2))\n",
    "    drop_cols = filter_corr(corr, cutoff)\n",
    "    print(list(drop_cols))\n",
    "    df.drop(list(drop_cols),inplace = True, axis = 1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def statistics_feature(df, agg_stat, acutoff=0.96)\n",
    "    # 数据处理\n",
    "    group_df3 = cunkuan[(cunkuan['mon']<=9)&(cunkuan['mon']>=7)].groupby(['cust_no']).agg(agg_stat)\n",
    "    group_df3.columns = [f[0]+'_'+f[1] for f in group_df3.columns]\n",
    "    group_df3.reset_index(inplace=True)\n",
    "    group_df3['season'] = 3\n",
    "\n",
    "    group_df4 = cunkuan[(cunkuan['mon']<=12)&(cunkuan['mon']>=10)].groupby(['cust_no']).agg(agg_stat)\n",
    "    col = [f[0]+'_'+f[1] for f in group_df4.columns]\n",
    "    group_df4.columns = [f[0]+'_'+f[1] for f in group_df4.columns]\n",
    "    group_df4.reset_index(inplace=True)\n",
    "    group_df4['season'] = 4\n",
    "\n",
    "    group_df1 = cunkuan[(cunkuan['mon']<=15)&(cunkuan['mon']>=13)].groupby(['cust_no']).agg(agg_stat)\n",
    "    group_df1.columns = [f[0]+'_'+f[1] for f in group_df1.columns]\n",
    "    group_df1.reset_index(inplace=True)\n",
    "    group_df1['season'] = 5\n",
    "                           \n",
    "    cunkuan_stat = pd.concat([pd.concat([group_df3, group_df4], axis=0, ignore_index=True), group_df1], axis=0, ignore_index=True)\n",
    "    del group_df3, group_df4, group_df1      \n",
    "    \n",
    "    # 剔除高度相关特征\n",
    "    cunkuan_stat = drop_correlated_col(cunkuan_stat, cutoff)\n",
    "    \n",
    "    # 将特征合并进去         \n",
    "    train, test = merge_feat(train, test, cunkuan_stat)\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征工程2\n",
    "#### 2. 用户存款(cunkuan)的季内和季间的变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Fluction_Feature(df_fea, train, test, f):\n",
    "    df_fea = df_fea[~df_fea['cust_no'].isnull()] #去除id为空的行\n",
    "    stat = pd.DataFrame(df_fea[['cust_no']].drop_duplicates())#去除重复值\n",
    "    for i in range(7,16):\n",
    "        tmp = df_fea[(df_fea['mon']==i)][['cust_no', f]].copy()\n",
    "        stat = stat.merge(tmp, on=['cust_no'], how='left')\n",
    "        print(stat.shape)\n",
    "    stat.fillna(value=0, inplace=True)\n",
    "    stat.columns =['cust_no'] + [f + '_' + str(i) for i in range(7, 16)]\n",
    "    # 季度内波动\n",
    "    stat[f+'_3s'] = stat[f +'_9'] - stat[f +'_7']\n",
    "    stat[f+'_4s'] = stat[f +'_12'] - stat[f +'_10']\n",
    "    stat[f+'_5s'] = stat[f +'_15'] - stat[f +'_13']\n",
    "    # 季度间波动\n",
    "    stat[f+'_34s'] = stat[f +'_12'] - stat[f +'_9']\n",
    "    stat[f+'_45s'] = stat[f +'_15'] - stat[f +'_12']\n",
    "\n",
    "\n",
    "    tmp = stat[['cust_no', f+'_9', f+'_12', f+'_3s', f+'_4s', f+'_34s']].copy()\n",
    "    tmp.columns = ['cust_no'] + [f+'_'+str(i) for i in range(1,6)]\n",
    "    train = train.merge(tmp, on=['cust_no'], how='left')\n",
    "    del tmp\n",
    "\n",
    "    tmp = stat[['cust_no',f+'_12', f+'_15', f+'_4s', f+'_5s',f+'_45s']].copy()\n",
    "    tmp.columns = ['cust_no'] + [f+'_'+str(i) for i in range(1,6)]\n",
    "    test = test.merge(tmp, on=['cust_no'], how='left')\n",
    "    del tmp\n",
    "    return train, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(254839, 2)\n",
      "(254839, 3)\n",
      "(254839, 4)\n",
      "(254839, 5)\n",
      "(254839, 6)\n",
      "(254839, 7)\n",
      "(254839, 8)\n",
      "(254839, 9)\n",
      "(254839, 10)\n"
     ]
    }
   ],
   "source": [
    "train, test =  get_Fluction_Feature(cunkuan, train, test, 'C1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(254839, 2)\n",
      "(254839, 3)\n",
      "(254839, 4)\n",
      "(254839, 5)\n",
      "(254839, 6)\n",
      "(254839, 7)\n",
      "(254839, 8)\n",
      "(254839, 9)\n",
      "(254839, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_no</th>\n",
       "      <th>C1_7</th>\n",
       "      <th>C1_8</th>\n",
       "      <th>C1_9</th>\n",
       "      <th>C1_10</th>\n",
       "      <th>C1_11</th>\n",
       "      <th>C1_12</th>\n",
       "      <th>C1_13</th>\n",
       "      <th>C1_14</th>\n",
       "      <th>C1_15</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0xb2d3ad96</td>\n",
       "      <td>332174.06</td>\n",
       "      <td>332005.48</td>\n",
       "      <td>331893.29</td>\n",
       "      <td>231097.73</td>\n",
       "      <td>231097.73</td>\n",
       "      <td>125081.24</td>\n",
       "      <td>125021.24</td>\n",
       "      <td>125021.24</td>\n",
       "      <td>103040.20</td>\n",
       "      <td>331893.29</td>\n",
       "      <td>125081.24</td>\n",
       "      <td>103040.20</td>\n",
       "      <td>-280.77</td>\n",
       "      <td>-106016.49</td>\n",
       "      <td>-21981.04</td>\n",
       "      <td>-206812.05</td>\n",
       "      <td>-22041.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0xb2d40f1c</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.34</td>\n",
       "      <td>5.34</td>\n",
       "      <td>5.34</td>\n",
       "      <td>5.35</td>\n",
       "      <td>5.35</td>\n",
       "      <td>5.35</td>\n",
       "      <td>5.36</td>\n",
       "      <td>5.34</td>\n",
       "      <td>5.35</td>\n",
       "      <td>5.36</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xb2d6bb22</td>\n",
       "      <td>7260.50</td>\n",
       "      <td>10060.90</td>\n",
       "      <td>10466.58</td>\n",
       "      <td>13808.58</td>\n",
       "      <td>17117.90</td>\n",
       "      <td>16023.22</td>\n",
       "      <td>23473.22</td>\n",
       "      <td>18249.22</td>\n",
       "      <td>17566.58</td>\n",
       "      <td>10466.58</td>\n",
       "      <td>16023.22</td>\n",
       "      <td>17566.58</td>\n",
       "      <td>3206.08</td>\n",
       "      <td>2214.64</td>\n",
       "      <td>-5906.64</td>\n",
       "      <td>5556.64</td>\n",
       "      <td>1543.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0xb2d6bb1f</td>\n",
       "      <td>40032.65</td>\n",
       "      <td>40006.70</td>\n",
       "      <td>40945.59</td>\n",
       "      <td>42322.89</td>\n",
       "      <td>40086.64</td>\n",
       "      <td>43102.03</td>\n",
       "      <td>40240.51</td>\n",
       "      <td>46855.37</td>\n",
       "      <td>45245.03</td>\n",
       "      <td>40945.59</td>\n",
       "      <td>43102.03</td>\n",
       "      <td>45245.03</td>\n",
       "      <td>912.94</td>\n",
       "      <td>779.14</td>\n",
       "      <td>5004.52</td>\n",
       "      <td>2156.44</td>\n",
       "      <td>2143.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xb2d3d20b</td>\n",
       "      <td>120007.40</td>\n",
       "      <td>120007.40</td>\n",
       "      <td>140007.62</td>\n",
       "      <td>140007.62</td>\n",
       "      <td>140007.62</td>\n",
       "      <td>140230.85</td>\n",
       "      <td>40000.18</td>\n",
       "      <td>40000.18</td>\n",
       "      <td>40007.27</td>\n",
       "      <td>140007.62</td>\n",
       "      <td>140230.85</td>\n",
       "      <td>40007.27</td>\n",
       "      <td>20000.22</td>\n",
       "      <td>223.23</td>\n",
       "      <td>7.09</td>\n",
       "      <td>223.23</td>\n",
       "      <td>-100223.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254834</th>\n",
       "      <td>0xb2dbcd91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254835</th>\n",
       "      <td>0xb2dbd307</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254836</th>\n",
       "      <td>0xb2dbe90c</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4355.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4355.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4355.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4355.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254837</th>\n",
       "      <td>0xb2dbe960</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>918.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>918.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>918.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>918.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254838</th>\n",
       "      <td>0xb2db6752</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>254839 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           cust_no       C1_7       C1_8       C1_9      C1_10      C1_11  \\\n",
       "0       0xb2d3ad96  332174.06  332005.48  331893.29  231097.73  231097.73   \n",
       "1       0xb2d40f1c       5.33       5.33       5.34       5.34       5.34   \n",
       "2       0xb2d6bb22    7260.50   10060.90   10466.58   13808.58   17117.90   \n",
       "3       0xb2d6bb1f   40032.65   40006.70   40945.59   42322.89   40086.64   \n",
       "4       0xb2d3d20b  120007.40  120007.40  140007.62  140007.62  140007.62   \n",
       "...            ...        ...        ...        ...        ...        ...   \n",
       "254834  0xb2dbcd91       0.00       0.00       0.00       0.00       0.00   \n",
       "254835  0xb2dbd307       0.00       0.00       0.00       0.00       0.00   \n",
       "254836  0xb2dbe90c       0.00       0.00       0.00       0.00       0.00   \n",
       "254837  0xb2dbe960       0.00       0.00       0.00       0.00       0.00   \n",
       "254838  0xb2db6752       0.00       0.00       0.00       0.00       0.00   \n",
       "\n",
       "            C1_12      C1_13      C1_14      C1_15         C1         C2  \\\n",
       "0       125081.24  125021.24  125021.24  103040.20  331893.29  125081.24   \n",
       "1            5.35       5.35       5.35       5.36       5.34       5.35   \n",
       "2        16023.22   23473.22   18249.22   17566.58   10466.58   16023.22   \n",
       "3        43102.03   40240.51   46855.37   45245.03   40945.59   43102.03   \n",
       "4       140230.85   40000.18   40000.18   40007.27  140007.62  140230.85   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "254834       0.00       0.00       0.00       0.00       0.00       0.00   \n",
       "254835       0.00       0.00       0.00       2.00       0.00       0.00   \n",
       "254836       0.00       0.00       0.00    4355.28       0.00       0.00   \n",
       "254837       0.00       0.00       0.00     918.15       0.00       0.00   \n",
       "254838       0.00       0.00       0.00       1.00       0.00       0.00   \n",
       "\n",
       "               C3        C4         C5        C6         C7         C8  \n",
       "0       103040.20   -280.77 -106016.49 -21981.04 -206812.05  -22041.04  \n",
       "1            5.36      0.01       0.01      0.01       0.01       0.01  \n",
       "2        17566.58   3206.08    2214.64  -5906.64    5556.64    1543.36  \n",
       "3        45245.03    912.94     779.14   5004.52    2156.44    2143.00  \n",
       "4        40007.27  20000.22     223.23      7.09     223.23 -100223.58  \n",
       "...           ...       ...        ...       ...        ...        ...  \n",
       "254834       0.00      0.00       0.00      0.00       0.00       0.00  \n",
       "254835       2.00      0.00       0.00      2.00       0.00       2.00  \n",
       "254836    4355.28      0.00       0.00   4355.28       0.00    4355.28  \n",
       "254837     918.15      0.00       0.00    918.15       0.00     918.15  \n",
       "254838       1.00      0.00       0.00      1.00       0.00       1.00  \n",
       "\n",
       "[254839 rows x 18 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cunkuan = cunkuan[~cunkuan['cust_no'].isnull()] #去除id为空的行\n",
    "cunkuan_stat = pd.DataFrame(cunkuan[['cust_no']].drop_duplicates())#去除重复值\n",
    "\n",
    "for i in range(7,16):\n",
    "    tmp = cunkuan[(cunkuan['mon']==i)][['cust_no', 'C1']].copy()\n",
    "    cunkuan_stat = cunkuan_stat.merge(tmp, on=['cust_no'], how='left')\n",
    "    print(cunkuan_stat.shape)\n",
    "cunkuan_stat.columns = ['cust_no'] + ['C1_'+ str(i)for i in range(7,16)]\n",
    "cunkuan_stat.fillna(0, inplace=True)\n",
    "# 静态\n",
    "cunkuan_stat['C1'] =  cunkuan_stat['C1_9']  \n",
    "cunkuan_stat['C2'] =  cunkuan_stat['C1_12']  \n",
    "cunkuan_stat['C3'] =  cunkuan_stat['C1_15']  \n",
    "# 季度内\n",
    "cunkuan_stat['C4'] =  cunkuan_stat['C1_9'] - cunkuan_stat['C1_7']   \n",
    "cunkuan_stat['C5'] = cunkuan_stat['C1_12'] - cunkuan_stat['C1_10']\n",
    "cunkuan_stat['C6'] = cunkuan_stat['C1_15'] - cunkuan_stat['C1_13']\n",
    "# 季度间\n",
    "cunkuan_stat['C7'] = cunkuan_stat['C1_12'] - cunkuan_stat['C1_9'] \n",
    "cunkuan_stat['C8'] = cunkuan_stat['C1_15'] - cunkuan_stat['C1_12'] \n",
    "\n",
    "cunkuan_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def drop_correlated_col(df, cutoff):\n",
    "    def filter_corr(corr, cutoff=0.7):\n",
    "        cols = []\n",
    "        for i,j in feature_group:\n",
    "            if corr.loc[i, j] > cutoff:\n",
    "                print(i,j,corr.loc[i, j])\n",
    "                i_avg = corr[i][corr[i] != 1].mean()\n",
    "                j_avg = corr[j][corr[j] != 1].mean()\n",
    "                if i_avg >= j_avg:\n",
    "                    cols.append(i)\n",
    "                else:\n",
    "                    cols.append(j)\n",
    "        return set(cols)\n",
    "\n",
    "    corr = df.corr()\n",
    "    feature_group = list(itertools.combinations(corr.columns, 2))\n",
    "    drop_cols = filter_corr(corr, cutoff)\n",
    "    print(list(drop_cols))\n",
    "    df.drop(list(drop_cols),inplace = True, axis = 1)\n",
    "    return df\n",
    "\n",
    "def merge_feat(train, test, df):\n",
    "    tmp = df[df['season']==3].copy()\n",
    "    del tmp['season']\n",
    "    tmp.columns = ['cust_no'] +  [f+'_1' for f in tmp.columns[1:]]\n",
    "    col_1 = [f for f in tmp.columns[1:]]\n",
    "    train = train.merge(tmp, on=['cust_no'], how='left')\n",
    "    train[col_1].fillna(value=0, inplace=True)\n",
    "\n",
    "\n",
    "    tmp = df[df['season']==4].copy()\n",
    "    del tmp['season']\n",
    "    tmp.columns = ['cust_no'] +  [f+'_2' for f in tmp.columns[1:]]\n",
    "    col_2 = [f for f in tmp.columns[1:]]\n",
    "    train = train.merge(tmp, on=['cust_no'], how='left')\n",
    "    train[col_2].fillna(value=0, inplace=True)\n",
    "\n",
    "\n",
    "    for i,j  in zip(col_1, col_2):\n",
    "        train[j+'_'+i] = train[j] - train[i]\n",
    "\n",
    "    tmp = df[df['season']==4].copy()\n",
    "    del tmp['season']\n",
    "    tmp.columns = ['cust_no'] +  [f+'_1' for f in tmp.columns[1:]]\n",
    "    col_1 = [f for f in tmp.columns[1:]]\n",
    "    test = test.merge(tmp, on=['cust_no'], how='left')\n",
    "    test[col_1].fillna(value=0, inplace=True)\n",
    "\n",
    "\n",
    "    tmp = df[df['season']==5].copy()\n",
    "    del tmp['season']\n",
    "    tmp.columns = ['cust_no'] +  [f+'_2' for f in tmp.columns[1:]]\n",
    "    col_2 = [f for f in tmp.columns[1:]]\n",
    "    test = test.merge(tmp, on=['cust_no'], how='left')\n",
    "    test[col_2].fillna(value=0, inplace=True)\n",
    "\n",
    "    for i,j  in zip(col_1, col_2):\n",
    "        test[j+'_'+i] = test[j] - test[i]\n",
    "        \n",
    "    return train, test\n",
    "\n",
    "cunkuan_stat = pd.read_pickle('cunkuan_stat.pkl')\n",
    "   \n",
    "cunkuan_stat = drop_correlated_col(cunkuan_stat, cutoff = 0.96)\n",
    "\n",
    "train, test = merge_feat(train, test, cunkuan_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cust_no                0.000000\n",
      "label                  0.000000\n",
      "bef_label              0.180819\n",
      "I1                     0.000000\n",
      "I2                     0.000000\n",
      "                         ...   \n",
      "C3_min_2_C3_min_1      0.113247\n",
      "C3_std_2_C3_std_1      0.157043\n",
      "C3_sum_2_C3_sum_1      0.113247\n",
      "C3_last_2_C3_last_1    0.113247\n",
      "C3_skew_2_C3_skew_1    0.193265\n",
      "Length: 69, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train.isnull().sum() / len(train))\n",
    "# tmp = cunkuan_stat[cunkuan_stat['season']==3].copy()\n",
    "# del tmp['season']\n",
    "# tmp.columns = ['cust_no'] +  [f+'_1' for f in tmp.columns[1:]]\n",
    "# col_1 = [f for f in tmp.columns[1:]]\n",
    "# train = train.merge(tmp, on=['cust_no'], how='left')\n",
    "# train[col_1].fillna(value=0, inplace=True)\n",
    "\n",
    "\n",
    "# tmp = cunkuan_stat[cunkuan_stat['season']==4].copy()\n",
    "# del tmp['season']\n",
    "# tmp.columns = ['cust_no'] +  [f+'_2' for f in tmp.columns[1:]]\n",
    "# col_2 = [f for f in tmp.columns[1:]]\n",
    "# train = train.merge(tmp, on=['cust_no'], how='left')\n",
    "# train[col_2].fillna(value=0, inplace=True)\n",
    "\n",
    "\n",
    "# for i,j  in zip(col_1, col_2):\n",
    "#     train[j+'_'+i] = train[j] - train[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eQJR3krsmh9Q",
    "outputId": "4675e70f-68e6-4a02-a57f-0c592555a614"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((76170, 53), (76722, 52))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4dJ4K4i6ptcP",
    "outputId": "309ba937-ee5f-4c2f-a072-85bc98da0566"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cust_no', 'label', 'bef_label', 'I1', 'I2', 'I3_x', 'I4', 'I5', 'I6',\n",
       "       'I10', 'I11', 'I13', 'I14', 'I16', 'I3_y', 'C1_min_1', 'C1_std_1',\n",
       "       'C1_skew_1', 'C2_min_1', 'C2_std_1', 'C2_skew_1', 'C3_max_1',\n",
       "       'C3_min_1', 'C3_std_1', 'C3_sum_1', 'C3_skew_1', 'C1_min_2', 'C1_std_2',\n",
       "       'C1_skew_2', 'C2_min_2', 'C2_std_2', 'C2_skew_2', 'C3_max_2',\n",
       "       'C3_min_2', 'C3_std_2', 'C3_sum_2', 'C3_skew_2', 'C1_min_2_C1_min_1',\n",
       "       'C1_std_2_C1_std_1', 'C1_skew_2_C1_skew_1', 'C2_min_2_C2_min_1',\n",
       "       'C2_std_2_C2_std_1', 'C2_skew_2_C2_skew_1', 'C3_max_2_C3_max_1',\n",
       "       'C3_min_2_C3_min_1', 'C3_std_2_C3_std_1', 'C3_sum_2_C3_sum_1',\n",
       "       'C3_skew_2_C3_skew_1', 'C1_1', 'C1_2', 'C1_3', 'C1_4', 'C1_5',\n",
       "       'X_sum_1', 'X_sum_2', 'X_sum_3', 'X_sum_4', 'X_sum_5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75eI8a53Nq1k"
   },
   "source": [
    "#### 资产数据(aum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Fluction_Feature(df_fea, train, test, f):\n",
    "#     f = 'X3'\n",
    "    df_fea = df_fea[~df_fea['cust_no'].isnull()] #去除id为空的行\n",
    "    stat = pd.DataFrame(df_fea[['cust_no']].drop_duplicates())#去除重复值\n",
    "    for i in range(7,16):\n",
    "        tmp = df_fea[(df_fea['mon']==i)][['cust_no', f]].copy()\n",
    "        stat = stat.merge(tmp, on=['cust_no'], how='left')\n",
    "        print(stat.shape)\n",
    "        \n",
    "    stat.fillna(value=0, inplace=True)#用0填充\n",
    "    stat.columns =['cust_no'] + [f + '_' + str(i) for i in range(7, 16)]\n",
    "    # 季度内波动\n",
    "    stat[f+'_3s'] = stat[f +'_9'] - stat[f +'_7']\n",
    "    stat[f+'_4s'] = stat[f +'_12'] - stat[f +'_10']\n",
    "    stat[f+'_5s'] = stat[f +'_15'] - stat[f +'_13']\n",
    "    # 季度间波动\n",
    "    stat[f+'_34s'] = stat[f +'_12'] - stat[f +'_9']\n",
    "    stat[f+'_45s'] = stat[f +'_15'] - stat[f +'_12']\n",
    "\n",
    "\n",
    "    tmp = stat[['cust_no', f+'_9', f+'_12', f+'_3s', f+'_4s', f+'_34s']].copy()\n",
    "    tmp.columns = ['cust_no'] + [f+'_'+str(i) for i in range(1,6)]\n",
    "    train = train.merge(tmp, on=['cust_no'], how='left')\n",
    "    del tmp\n",
    "\n",
    "    tmp = stat[['cust_no',f+'_12', f+'_15', f+'_4s', f+'_5s',f+'_45s']].copy()\n",
    "    tmp.columns = ['cust_no'] + [f+'_'+str(i) for i in range(1,6)]\n",
    "    test = test.merge(tmp, on=['cust_no'], how='left')\n",
    "    del tmp\n",
    "    return train, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(659624, 2)\n",
      "(659624, 3)\n",
      "(659624, 4)\n",
      "(659624, 5)\n",
      "(659624, 6)\n",
      "(659624, 7)\n",
      "(659624, 8)\n",
      "(659624, 9)\n",
      "(659624, 10)\n"
     ]
    }
   ],
   "source": [
    "X_cols = [f for f in aum.columns if f.startswith('X')]\n",
    "aum['X_sum'] = aum[X_cols].sum(axis=1)\n",
    "train, test =  get_Fluction_Feature(aum, train, test, 'X_sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2RiZgWQyqlHB",
    "outputId": "fec05e21-0289-47e8-8582-b35a52cada6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76170, 196) (76722, 195)\n"
     ]
    }
   ],
   "source": [
    "aum_stat = pd.read_pickle('aum_stat.pkl')\n",
    "aum_stat = drop_correlated_col(aum_stat, cutoff = 0.96)\n",
    "train, test = merge_feat(train, test, aum_stat)\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QIRirm2vNq1l"
   },
   "source": [
    "#### 3. 用户当季度最后一个月的行为数据(behavior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5dEhFgKNq1l"
   },
   "source": [
    "#### 4. 用户当季度的事件特征(event)，这里大多数都是时间，所以用该季度月末的后一天做时间差特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "tTmuuSX3Nq1l"
   },
   "outputs": [],
   "source": [
    "\n",
    "behavior['B5-B3'] = behavior['B5'] - behavior['B3']\n",
    "behavior['B4-B2'] = behavior['B4'] - behavior['B2']\n",
    "behavior['B3/B2'] = behavior['B3'] / behavior['B2']\n",
    "behavior['B5/B4'] = behavior['B5'] / behavior['B4']\n",
    "behavior['B4/B2'] = behavior['B4'] / behavior['B2']\n",
    "behavior['B5/B3'] = behavior['B5'] / behavior['B3']\n",
    "behavior['B6_hour'] =  pd.to_datetime(behavior['B6'] ).dt.hour\n",
    "behavior.loc[((behavior['mon']==9)),'B6'] =  (pd.to_datetime('2019-10-01 00:00:00') -pd.to_datetime(behavior.loc[((behavior['mon']==9)),'B6'])).dt.days\n",
    "behavior.loc[((behavior['mon']==12)),'B6'] =  (pd.to_datetime('2020-01-01 00:00:00')-pd.to_datetime(behavior.loc[((behavior['mon']==12)),'B6'])).dt.days\n",
    "behavior.loc[((behavior['mon']==15)),'B6'] =  (pd.to_datetime('2020-04-01 00:00:00') -pd.to_datetime(behavior.loc[((behavior['mon']==15)),'B6'])).dt.days\n",
    "\n",
    "# (pd.to_datetime('2019-10-01 00:00:00') -pd.to_datetime(behavior.loc[((behavior['mon']==9)),'B6'])).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_stat = {'B5-B3': ['max', 'min', 'std', 'sum', 'last', 'skew'],\n",
    "            'B4-B2': ['max', 'min', 'std', 'sum', 'last', 'skew'],\n",
    "            'B3/B2': ['max', 'min', 'std', 'sum', 'last', 'skew'],\n",
    "            'B5/B4': ['max', 'min', 'std', 'sum', 'last', 'skew'],\n",
    "            'B4/B2': ['max', 'min', 'std', 'sum', 'last', 'skew'],\n",
    "            'B5/B3': ['max', 'min', 'std', 'sum', 'last', 'skew'],\n",
    "            'B1': ['max', 'min', 'std', 'sum', 'last', 'skew'],\n",
    "            'B2': ['max', 'min', 'std', 'sum', 'last', 'skew'],\n",
    "            'B3': ['max', 'min', 'std', 'sum', 'last', 'skew'],\n",
    "            'B4': ['max', 'min', 'std', 'sum', 'last', 'skew'],\n",
    "            'B5': ['max', 'min', 'std', 'sum', 'last', 'skew'],\n",
    "             'B6': ['max'], \n",
    "            'B6_hour': ['max'], \n",
    "            'B7': ['max'],        \n",
    "           }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 456
    },
    "id": "hfNufAtjNq1l",
    "outputId": "8982e9cc-c980-4678-fdd3-2c92b794162d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B3/B2_min B3/B2_last 0.9714778417386742\n",
      "B5/B4_max B5/B4_sum 0.9612153008223376\n",
      "B5/B4_max B5/B4_last 0.9678604292715175\n",
      "B5/B4_min B5/B4_last 0.9690609554203113\n",
      "B5/B3_max B5/B3_min 0.9968893511806203\n",
      "B5/B3_max B5/B3_std 0.99752284106521\n",
      "B5/B3_max B5/B3_sum 0.9999999985612688\n",
      "B5/B3_max B5/B3_last 0.9969164322151617\n",
      "B5/B3_min B5/B3_sum 0.9968893437084174\n",
      "B5/B3_min B5/B3_last 0.9999728105501697\n",
      "B5/B3_std B5/B3_sum 0.997522396716309\n",
      "B5/B3_sum B5/B3_last 0.9969164276516074\n",
      "B3_max B3_std 0.9601763869847368\n",
      "B4_max B4_std 0.9651829078903473\n",
      "['B5/B4_sum', 'B5/B3_last', 'B4_max', 'B3_max', 'B3/B2_last', 'B5/B3_sum', 'B5/B3_max', 'B5/B4_max', 'B5/B4_last']\n",
      "(76170, 376) (76722, 375)\n"
     ]
    }
   ],
   "source": [
    "behavior_stat = pd.read_pickle('behavior_stat.pkl')\n",
    "behavior_stat = drop_correlated_col(behavior_stat, cutoff = 0.96)\n",
    "train, test = merge_feat(train, test, behavior_stat)\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 事件相关特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76170, 392) (76722, 391)\n"
     ]
    }
   ],
   "source": [
    "# event_feat = pd.read_pickle('event_feat_engineering1.pkl')\n",
    "# behavior_stat = drop_correlated_col(event_feat, cutoff = 0.96)\n",
    "train = train.merge(behavior_stat.loc[behavior_stat['flag']==1], on=['cust_no'], how='left')\n",
    "del train['flag']\n",
    "test = test.merge(behavior_stat.loc[behavior_stat['flag']==0], on=['cust_no'], how='left')\n",
    "del test['flag']\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 去掉和标签几乎完全不相关的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76170, 318) (76722, 317)\n"
     ]
    }
   ],
   "source": [
    "drop_cols = train.corr()['label'][abs(train.corr()['label'])<0.005].index\n",
    "test.drop(drop_cols,axis=1,inplace=True)\n",
    "train.drop(drop_cols,axis=1,inplace=True)\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加入权重信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['weight'] = train['label'].map({0:1.03,1:0.58,-1:1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 指定类别标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bef_label',\n",
       " 'I1',\n",
       " 'I2',\n",
       " 'I3_x',\n",
       " 'I4',\n",
       " 'I5',\n",
       " 'I6',\n",
       " 'I10',\n",
       " 'I13',\n",
       " 'I14',\n",
       " 'I16',\n",
       " 'I3_y']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cate_cols =['bef_label'] + [f for f in train.columns if f.startswith('I') and f not in  ['I11'] ] \n",
    "cate_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p_gZdEMJNq1m"
   },
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kREn0rJkNq1m"
   },
   "source": [
    "以上就构成了我们baseline的基础特征，下面开始训练模型。这里采用的是Lightgbm进行5折的多分类，早停直接使用kappa值。因为训练多分类时，目标值的最小值得是0，所以我们对原始label做+1的处理（记得提交的时候要改回来）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kappa(preds, train_data):\n",
    "    y_true = train_data.label\n",
    "    preds = np.argmax(preds.reshape(3, -1), axis=0)\n",
    "    score = cohen_kappa_score(y_true, preds)\n",
    "    return 'kappa', score, True\n",
    "\n",
    "def LGB_classfication_model(train, target, test, k):\n",
    "    feats = [f for f in train.columns if f not in ['cust_no', 'label', 'weight']]\n",
    "    print('Current num of features:', len(feats))\n",
    "    folds = KFold(n_splits=k, shuffle=False, random_state=2020)\n",
    "    oof_preds = np.zeros(train.shape[0])\n",
    "    oof_probs = np.zeros((train.shape[0], 3))\n",
    "    output_preds = []\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    offline_score = []\n",
    "    for i, (train_index, test_index) in enumerate(folds.split(train, target)):\n",
    "        train_y, test_y = target[train_index], target[test_index]\n",
    "        train_X, test_X = train[feats].iloc[train_index, :], train[feats].iloc[test_index, :]\n",
    "        print(train_X.shape, test_X.shape)\n",
    "        dtrain = lgb.Dataset(train_X,\n",
    "                             label=train_y,\n",
    "                             categorical_feature=cate_cols, \n",
    "                            )\n",
    "        dval = lgb.Dataset(test_X,\n",
    "                           label=test_y,\n",
    "                          categorical_feature=cate_cols, )\n",
    "        parameters = {\n",
    "            'learning_rate': 0.05,\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'multiclass',\n",
    "            'metric': 'None',\n",
    "            'num_leaves': 63,\n",
    "            'num_class': 3,\n",
    "            'feature_fraction': 0.8,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'min_data_in_leaf': 20,\n",
    "            'verbose': -1,\n",
    "            'nthread': 24\n",
    "        }\n",
    "        lgb_model = lgb.train(\n",
    "            parameters,\n",
    "            dtrain,\n",
    "            num_boost_round=5000,\n",
    "            valid_sets=[dval],\n",
    "            early_stopping_rounds=100,\n",
    "            verbose_eval=100,\n",
    "            feval=kappa, \n",
    "        )\n",
    "        oof_probs[test_index] = lgb_model.predict(test_X[feats], num_iteration=lgb_model.best_iteration)\n",
    "        oof_preds[test_index] = np.argmax(lgb_model.predict(test_X[feats], num_iteration=lgb_model.best_iteration), axis=1)\n",
    "        offline_score.append(lgb_model.best_score['valid_0']['kappa'])\n",
    "            \n",
    "\n",
    "        output_preds.append(lgb_model.predict(test[feats], num_iteration=lgb_model.best_iteration))\n",
    "        # feature importance\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = lgb_model.feature_importance(importance_type='gain')\n",
    "        fold_importance_df[\"fold\"] = i + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        \n",
    "    print('OOF-MEAN-KAPPA score:%.6f, OOF-STD:%.6f' % (np.mean(offline_score), np.std(offline_score)))\n",
    "    print('feature importance:')\n",
    "    print(feature_importance_df.groupby(['feature'])['importance'].mean().sort_values(ascending=False).head(15))\n",
    "    print('confusion matrix:')\n",
    "    print(confusion_matrix(target, oof_preds))\n",
    "    print('classfication report:')\n",
    "    print(classification_report(target, oof_preds))\n",
    "\n",
    "    return output_preds, oof_probs, np.mean(offline_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current num of features: 362\n",
      "(60936, 362) (15234, 362)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's kappa: 0.470796\n",
      "[200]\tvalid_0's kappa: 0.473298\n",
      "Early stopping, best iteration is:\n",
      "[194]\tvalid_0's kappa: 0.474366\n",
      "(60936, 362) (15234, 362)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's kappa: 0.465506\n",
      "[200]\tvalid_0's kappa: 0.466089\n",
      "Early stopping, best iteration is:\n",
      "[122]\tvalid_0's kappa: 0.467985\n",
      "(60936, 362) (15234, 362)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's kappa: 0.459165\n",
      "[200]\tvalid_0's kappa: 0.461454\n",
      "[300]\tvalid_0's kappa: 0.462316\n",
      "Early stopping, best iteration is:\n",
      "[269]\tvalid_0's kappa: 0.464943\n",
      "(60936, 362) (15234, 362)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's kappa: 0.449488\n",
      "[200]\tvalid_0's kappa: 0.449385\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's kappa: 0.453221\n",
      "(60936, 362) (15234, 362)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's kappa: 0.46275\n",
      "[200]\tvalid_0's kappa: 0.464099\n",
      "[300]\tvalid_0's kappa: 0.464755\n",
      "Early stopping, best iteration is:\n",
      "[261]\tvalid_0's kappa: 0.46572\n",
      "OOF-MEAN-KAPPA score:0.465247, OOF-STD:0.006864\n",
      "feature importance:\n",
      "feature\n",
      "X_sum_5         77490.381531\n",
      "X_sum_2         66609.156683\n",
      "X_sum_4         24619.611219\n",
      "X_sum_min_y     22244.283396\n",
      "C1_min_y        17602.213275\n",
      "C2_min_y        14954.807747\n",
      "C4              12114.139509\n",
      "X_sum_skew_y    10598.722656\n",
      "C5              10462.031696\n",
      "B7_max_y        10203.989067\n",
      "I3_x             8750.275381\n",
      "C2               6709.126417\n",
      "C1_skew_y        4885.109381\n",
      "X3_last_y        4871.319469\n",
      "B7_max_x         4776.357162\n",
      "Name: importance, dtype: float64\n",
      "confusion matrix:\n",
      "[[ 6279  1527  3781]\n",
      " [ 1297  5818  8072]\n",
      " [ 1469  3074 44853]]\n",
      "classfication report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.54      0.61     11587\n",
      "          1       0.56      0.38      0.45     15187\n",
      "          2       0.79      0.91      0.85     49396\n",
      "\n",
      "avg / total       0.73      0.75      0.73     76170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target = train['label'] + 1\n",
    "lgb_preds, lgb_oof, lgb_score = LGB_classfication_model(train, target, test, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46526508048401805\n"
     ]
    }
   ],
   "source": [
    "print(cohen_kappa_score(train['label'] + 1, np.argmax(lgb_oof, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 后处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用sp.optimize.minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "from functools import partial\n",
    "import scipy as sp\n",
    "\n",
    "def kappa_loss(weight, y_hat, y):\n",
    "    y_hat = weight*y_hat\n",
    "    loss = cohen_kappa_score(y, np.argmax(y_hat, axis=1))\n",
    "    return -loss\n",
    "\n",
    "def get_weights(y_hat, y):\n",
    "    size = np.unique(y).size\n",
    "    loss_partial = partial(kappa_loss, y_hat=y_hat, y=y)\n",
    "    initial_weights = [1. for _ in range(size)]\n",
    "    weights_ = sp.optimize.minimize(loss_partial, initial_weights, method='Nelder-Mead')\n",
    "    return weights_['x']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "权重为 [1.45716273 1.11638232 0.64310668]\n",
      "0.48918081744161745\n"
     ]
    }
   ],
   "source": [
    "weights = get_weights(lgb_oof, train['label'] + 1)\n",
    "print('权重为',weights)\n",
    "print(cohen_kappa_score(train['label'] + 1, np.argmax(lgb_oof @ np.diag(weights), axis=1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 贝叶斯搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "def get_bayes_weights(y_hat, y):\n",
    "    def kappa_calc(x1, x2, x3):\n",
    "        pred_y = np.array([x1, x2, x3])*y_hat\n",
    "        loss = cohen_kappa_score(y, np.argmax(pred_y, axis=1))\n",
    "        return loss\n",
    "\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=kappa_calc,\n",
    "        pbounds={\n",
    "            \"x1\": (0, 3),\n",
    "            \"x2\": (0, 3),\n",
    "            \"x3\": (0, 3),\n",
    "        },\n",
    "        random_state=1,\n",
    "        verbose=0\n",
    "    )\n",
    "    optimizer.maximize()\n",
    "    weights_ = optimizer.max['params']\n",
    "    weights_ = np.array([weights_['x1'], weights_['x2'], weights_['x3']])\n",
    "    return weights_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48466115374052543\n"
     ]
    }
   ],
   "source": [
    "bayes_weights =  get_bayes_weights(lgb_oof, train['label'] + 1)\n",
    "\n",
    "print(cohen_kappa_score(train['label'] + 1, np.argmax(lgb_oof @ np.diag(bayes_weights), axis=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kappa(preds, train_data):\n",
    "    y_true = train_data.label\n",
    "    preds = np.argmax(preds.reshape(3, -1), axis=0)\n",
    "    score = cohen_kappa_score(y_true, preds)\n",
    "    return 'kappa', score, True\n",
    "\n",
    "def LGB_classfication_model(train, target, test, k):\n",
    "    feats = [f for f in train.columns if f not in ['cust_no', 'label', 'weight']]\n",
    "    print('Current num of features:', len(feats))\n",
    "    folds = KFold(n_splits=k, shuffle=False, random_state=2020)\n",
    "    oof_preds = np.zeros(train.shape[0])\n",
    "    oof_probs = np.zeros((train.shape[0], 3))\n",
    "    output_preds = []\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    offline_score = []\n",
    "    for i, (train_index, test_index) in enumerate(folds.split(train, target)):\n",
    "        train_y, test_y = target[train_index], target[test_index]\n",
    "        train_X, test_X = train[feats].iloc[train_index, :], train[feats].iloc[test_index, :]\n",
    "        train_weight, valid_weight = train['weight'][train_index], train['weight'][test_index]\n",
    "        print(train_X.shape, test_X.shape)\n",
    "        dtrain = lgb.Dataset(train_X,\n",
    "                             label=train_y,\n",
    "                             categorical_feature=cate_cols, \n",
    "                             weight=train_weight.values.flatten(order='F'),\n",
    "                            )\n",
    "        dval = lgb.Dataset(test_X,\n",
    "                           label=test_y,\n",
    "                          categorical_feature=cate_cols, )\n",
    "        parameters = {\n",
    "            'learning_rate': 0.05,\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'multiclass',\n",
    "            'metric': 'None',\n",
    "            'num_leaves': 63,\n",
    "            'num_class': 3,\n",
    "            'feature_fraction': 0.8,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'min_data_in_leaf': 20,\n",
    "            'verbose': -1,\n",
    "            'nthread': 24\n",
    "        }\n",
    "        lgb_model = lgb.train(\n",
    "            parameters,\n",
    "            dtrain,\n",
    "            num_boost_round=5000,\n",
    "            valid_sets=[dval],\n",
    "            early_stopping_rounds=100,\n",
    "            verbose_eval=100,\n",
    "            feval=kappa, \n",
    "        )\n",
    "        oof_probs[test_index] = lgb_model.predict(test_X[feats], num_iteration=lgb_model.best_iteration)\n",
    "        oof_preds[test_index] = np.argmax(lgb_model.predict(test_X[feats], num_iteration=lgb_model.best_iteration), axis=1)\n",
    "        offline_score.append(lgb_model.best_score['valid_0']['kappa'])\n",
    "            \n",
    "\n",
    "        output_preds.append(lgb_model.predict(test[feats], num_iteration=lgb_model.best_iteration))\n",
    "        # feature importance\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = lgb_model.feature_importance(importance_type='gain')\n",
    "        fold_importance_df[\"fold\"] = i + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    print('OOF-MEAN-KAPPA score:%.6f, OOF-STD:%.6f' % (np.mean(offline_score), np.std(offline_score)))\n",
    "    print('feature importance:')\n",
    "    print(feature_importance_df.groupby(['feature'])['importance'].mean().sort_values(ascending=False).head(15))\n",
    "    print('confusion matrix:')\n",
    "    print(confusion_matrix(target, oof_preds))\n",
    "    print('classfication report:')\n",
    "    print(classification_report(target, oof_preds))\n",
    "\n",
    "    return output_preds, oof_probs, np.mean(offline_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current num of features: 362\n",
      "(60936, 362) (15234, 362)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's kappa: 0.493764\n",
      "[200]\tvalid_0's kappa: 0.498521\n",
      "Early stopping, best iteration is:\n",
      "[188]\tvalid_0's kappa: 0.499305\n",
      "(60936, 362) (15234, 362)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's kappa: 0.484062\n",
      "[200]\tvalid_0's kappa: 0.488291\n",
      "Early stopping, best iteration is:\n",
      "[162]\tvalid_0's kappa: 0.48893\n",
      "(60936, 362) (15234, 362)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's kappa: 0.472903\n",
      "[200]\tvalid_0's kappa: 0.477027\n",
      "[300]\tvalid_0's kappa: 0.475891\n",
      "Early stopping, best iteration is:\n",
      "[213]\tvalid_0's kappa: 0.479163\n",
      "(60936, 362) (15234, 362)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's kappa: 0.483272\n",
      "[200]\tvalid_0's kappa: 0.481256\n",
      "Early stopping, best iteration is:\n",
      "[131]\tvalid_0's kappa: 0.485338\n",
      "(60936, 362) (15234, 362)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's kappa: 0.493065\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's kappa: 0.496558\n",
      "OOF-MEAN-KAPPA score:0.489859, OOF-STD:0.007346\n",
      "feature importance:\n",
      "feature\n",
      "X_sum_5         60963.370267\n",
      "X_sum_2         57264.460471\n",
      "X_sum_min_y     21139.773995\n",
      "X_sum_4         18971.919449\n",
      "C1_min_y        15126.798401\n",
      "C2_min_y        14449.590827\n",
      "C4              10292.273475\n",
      "B7_max_y         9344.045695\n",
      "X_sum_skew_y     8578.877589\n",
      "C5               7697.353514\n",
      "I3_x             5743.436492\n",
      "C2               5659.520112\n",
      "B7_max_x         4446.842709\n",
      "X3_last_y        3770.270954\n",
      "X_sum_std_y      3628.298240\n",
      "Name: importance, dtype: float64\n",
      "confusion matrix:\n",
      "[[ 6619  2346  2622]\n",
      " [ 1494  8214  5479]\n",
      " [ 1889  6200 41307]]\n",
      "classfication report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.57      0.61     11587\n",
      "          1       0.49      0.54      0.51     15187\n",
      "          2       0.84      0.84      0.84     49396\n",
      "\n",
      "avg / total       0.74      0.74      0.74     76170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target = train['label'] + 1\n",
    "lgb_preds, lgb_oof, lgb_score = LGB_classfication_model(train, target, test, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4898882468809378\n"
     ]
    }
   ],
   "source": [
    "print(cohen_kappa_score(train['label'] + 1, np.argmax(lgb_oof, axis=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    0.633495\n",
       " 0    0.225307\n",
       "-1    0.141198\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = test[['cust_no']].copy()\n",
    "sub_df['label'] = np.argmax(np.mean(lgb_preds, axis=0), axis=1) - 1\n",
    "sub_df['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kappa(preds, train_data):\n",
    "    y_true = train_data.label\n",
    "    preds = np.argmax(preds.reshape(3, -1), axis=0)\n",
    "    score = cohen_kappa_score(y_true, preds)\n",
    "    return 'kappa', score, True\n",
    "\n",
    "def LGB_classfication_model(train, target, test, k):\n",
    "    feats = [f for f in train.columns if f not in ['cust_no', 'label', 'weight']]\n",
    "    print('Current num of features:', len(feats))\n",
    "    folds = StratifiedKFold(n_splits=k, shuffle=True, random_state=2020)\n",
    "    oof_preds = np.zeros(train.shape[0])\n",
    "    oof_probs = np.zeros((train.shape[0], 3))\n",
    "    output_preds = []\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    offline_score = []\n",
    "    for i, (train_index, test_index) in enumerate(folds.split(train, target)):\n",
    "        train_y, test_y = target[train_index], target[test_index]\n",
    "        train_X, test_X = train[feats].iloc[train_index, :], train[feats].iloc[test_index, :]\n",
    "        train_weight, valid_weight = train['weight'][train_index], train['weight'][test_index]\n",
    "        print(train_X.shape, test_X.shape)\n",
    "        dtrain = lgb.Dataset(train_X,\n",
    "                             label=train_y,\n",
    "                             categorical_feature=cate_cols, \n",
    "                             weight=train_weight.values.flatten(order='F'),\n",
    "                            )\n",
    "        dval = lgb.Dataset(test_X,\n",
    "                           label=test_y,\n",
    "                          categorical_feature=cate_cols, )\n",
    "        parameters = {\n",
    "            'learning_rate': 0.05,\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'multiclass',\n",
    "            'metric': 'None',\n",
    "            'num_leaves': 63,\n",
    "            'num_class': 3,\n",
    "            'feature_fraction': 0.8,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'min_data_in_leaf': 20,\n",
    "            'verbose': -1,\n",
    "            'nthread': 24\n",
    "        }\n",
    "        lgb_model = lgb.train(\n",
    "            parameters,\n",
    "            dtrain,\n",
    "            num_boost_round=5000,\n",
    "            valid_sets=[dval],\n",
    "            early_stopping_rounds=100,\n",
    "            verbose_eval=100,\n",
    "            feval=kappa, \n",
    "        )\n",
    "        oof_probs[test_index] = lgb_model.predict(test_X[feats], num_iteration=lgb_model.best_iteration)\n",
    "        oof_preds[test_index] = np.argmax(lgb_model.predict(test_X[feats], num_iteration=lgb_model.best_iteration), axis=1)\n",
    "        offline_score.append(lgb_model.best_score['valid_0']['kappa'])\n",
    "            \n",
    "\n",
    "        output_preds.append(lgb_model.predict(test[feats], num_iteration=lgb_model.best_iteration))\n",
    "        # feature importance\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = lgb_model.feature_importance(importance_type='gain')\n",
    "        fold_importance_df[\"fold\"] = i + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    print('OOF-MEAN-KAPPA score:%.6f, OOF-STD:%.6f' % (np.mean(offline_score), np.std(offline_score)))\n",
    "    print('feature importance:')\n",
    "    print(feature_importance_df.groupby(['feature'])['importance'].mean().sort_values(ascending=False).head(15))\n",
    "    print('confusion matrix:')\n",
    "    print(confusion_matrix(target, oof_preds))\n",
    "    print('classfication report:')\n",
    "    print(classification_report(target, oof_preds))\n",
    "\n",
    "    return output_preds, oof_probs, np.mean(offline_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current num of features: 362\n",
      "(60934, 362) (15236, 362)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's kappa: 0.485067\n",
      "[200]\tvalid_0's kappa: 0.482683\n",
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's kappa: 0.487408\n",
      "(60935, 362) (15235, 362)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's kappa: 0.491094\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's kappa: 0.492062\n",
      "(60937, 362) (15233, 362)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's kappa: 0.494069\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's kappa: 0.49547\n",
      "(60937, 362) (15233, 362)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's kappa: 0.482474\n",
      "[200]\tvalid_0's kappa: 0.485149\n",
      "[300]\tvalid_0's kappa: 0.48635\n",
      "Early stopping, best iteration is:\n",
      "[243]\tvalid_0's kappa: 0.488465\n",
      "(60937, 362) (15233, 362)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's kappa: 0.48066\n",
      "[200]\tvalid_0's kappa: 0.484375\n",
      "[300]\tvalid_0's kappa: 0.480965\n",
      "Early stopping, best iteration is:\n",
      "[203]\tvalid_0's kappa: 0.484768\n",
      "OOF-MEAN-KAPPA score:0.489635, OOF-STD:0.003740\n",
      "feature importance:\n",
      "feature\n",
      "X_sum_5         61021.418590\n",
      "X_sum_2         56344.419786\n",
      "X_sum_min_y     21475.271476\n",
      "X_sum_4         18772.428125\n",
      "C1_min_y        15572.602065\n",
      "C2_min_y        13923.026149\n",
      "C4               9821.552161\n",
      "B7_max_y         9623.751029\n",
      "X_sum_skew_y     8465.905435\n",
      "C5               7792.748744\n",
      "I3_x             5734.907053\n",
      "C2               5486.944799\n",
      "B7_max_x         3883.345148\n",
      "X3_last_y        3638.978747\n",
      "E15              3431.488505\n",
      "Name: importance, dtype: float64\n",
      "confusion matrix:\n",
      "[[ 6641  2350  2596]\n",
      " [ 1487  8228  5472]\n",
      " [ 1899  6260 41237]]\n",
      "classfication report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.57      0.61     11587\n",
      "          1       0.49      0.54      0.51     15187\n",
      "          2       0.84      0.83      0.84     49396\n",
      "\n",
      "avg / total       0.74      0.74      0.74     76170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target = train['label'] + 1\n",
    "lgb_preds, lgb_oof, lgb_score = LGB_classfication_model(train, target, test, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_no</th>\n",
       "      <th>label</th>\n",
       "      <th>prba1</th>\n",
       "      <th>prba2</th>\n",
       "      <th>prba3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x3b9b4615</td>\n",
       "      <td>1</td>\n",
       "      <td>0.064529</td>\n",
       "      <td>0.426921</td>\n",
       "      <td>0.508550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x3b9ae61b</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023218</td>\n",
       "      <td>0.114226</td>\n",
       "      <td>0.862556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x3b9add69</td>\n",
       "      <td>1</td>\n",
       "      <td>0.044682</td>\n",
       "      <td>0.194048</td>\n",
       "      <td>0.761270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x3b9b3601</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014320</td>\n",
       "      <td>0.724767</td>\n",
       "      <td>0.260913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x3b9b2599</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013054</td>\n",
       "      <td>0.508893</td>\n",
       "      <td>0.478053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76717</th>\n",
       "      <td>0xb2d69017</td>\n",
       "      <td>1</td>\n",
       "      <td>0.119785</td>\n",
       "      <td>0.265532</td>\n",
       "      <td>0.614684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76718</th>\n",
       "      <td>0xb2d68153</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010656</td>\n",
       "      <td>0.163321</td>\n",
       "      <td>0.826024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76719</th>\n",
       "      <td>0xb2d5bba1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.073333</td>\n",
       "      <td>0.206951</td>\n",
       "      <td>0.719716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76720</th>\n",
       "      <td>0xb2d61b9b</td>\n",
       "      <td>1</td>\n",
       "      <td>0.056048</td>\n",
       "      <td>0.134226</td>\n",
       "      <td>0.809726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76721</th>\n",
       "      <td>0xb2d70079</td>\n",
       "      <td>0</td>\n",
       "      <td>0.149579</td>\n",
       "      <td>0.599429</td>\n",
       "      <td>0.250992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76722 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          cust_no  label     prba1     prba2     prba3\n",
       "0      0x3b9b4615      1  0.064529  0.426921  0.508550\n",
       "1      0x3b9ae61b      1  0.023218  0.114226  0.862556\n",
       "2      0x3b9add69      1  0.044682  0.194048  0.761270\n",
       "3      0x3b9b3601      0  0.014320  0.724767  0.260913\n",
       "4      0x3b9b2599      0  0.013054  0.508893  0.478053\n",
       "...           ...    ...       ...       ...       ...\n",
       "76717  0xb2d69017      1  0.119785  0.265532  0.614684\n",
       "76718  0xb2d68153      1  0.010656  0.163321  0.826024\n",
       "76719  0xb2d5bba1      1  0.073333  0.206951  0.719716\n",
       "76720  0xb2d61b9b      1  0.056048  0.134226  0.809726\n",
       "76721  0xb2d70079      0  0.149579  0.599429  0.250992\n",
       "\n",
       "[76722 rows x 5 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sub_df[['prba1', 'prba2', 'prba3']] = np.mean(lgb_preds, axis=0)\n",
    "sub_df.to_csv('lgb26_prab.csv', index=False)\n",
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    0.630210\n",
       " 0    0.236308\n",
       "-1    0.133482\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = test[['cust_no']].copy()\n",
    "sub_df['label'] = np.argmax(np.mean(lgb_preds, axis=0), axis=1) - 1\n",
    "sub_df['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv('lgb26.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kappa(preds, train_data):\n",
    "    y_true = train_data.label\n",
    "    preds = np.argmax(preds.reshape(3, -1), axis=0)\n",
    "    score = cohen_kappa_score(y_true, preds)\n",
    "    return 'kappa', score, True\n",
    "\n",
    "def LGB_classfication_model(train, target, test, k):\n",
    "    feats = [f for f in train.columns if f not in ['cust_no', 'label', 'weight']]\n",
    "    print('Current num of features:', len(feats))\n",
    "    folds = StratifiedKFold(n_splits=k, shuffle=True, random_state=2020)\n",
    "    oof_preds = np.zeros(train.shape[0])\n",
    "    oof_probs = np.zeros((train.shape[0], 3))\n",
    "    output_preds = []\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    offline_score = []\n",
    "    for i, (train_index, test_index) in enumerate(folds.split(train, target)):\n",
    "        train_y, test_y = target[train_index], target[test_index]\n",
    "        train_X, test_X = train[feats].iloc[train_index, :], train[feats].iloc[test_index, :]\n",
    "        train_weight, valid_weight = train['weight'][train_index], train['weight'][test_index]\n",
    "        print(train_X.shape, test_X.shape)\n",
    "        dtrain = lgb.Dataset(train_X,\n",
    "                             label=train_y,\n",
    "                             categorical_feature=cate_cols, \n",
    "                             weight=train_weight.values.flatten(order='F'),\n",
    "                            )\n",
    "        dval = lgb.Dataset(test_X,\n",
    "                           label=test_y,\n",
    "                          categorical_feature=cate_cols, )\n",
    "        parameters = {\n",
    "            'learning_rate': 0.05,\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'multiclass',\n",
    "            'metric': 'None',\n",
    "            'num_leaves': 63,\n",
    "            'num_class': 3,\n",
    "            'feature_fraction': 0.7,\n",
    "            'bagging_fraction': 0.7,\n",
    "            'min_data_in_leaf': 20,\n",
    "            'verbose': -1,\n",
    "            'nthread': 24\n",
    "        }\n",
    "        lgb_model = lgb.train(\n",
    "            parameters,\n",
    "            dtrain,\n",
    "            num_boost_round=5000,\n",
    "            valid_sets=[dval],\n",
    "            early_stopping_rounds=100,\n",
    "            verbose_eval=100,\n",
    "            feval=kappa, \n",
    "        )\n",
    "        oof_probs[test_index] = lgb_model.predict(test_X[feats], num_iteration=lgb_model.best_iteration)\n",
    "        oof_preds[test_index] = np.argmax(lgb_model.predict(test_X[feats], num_iteration=lgb_model.best_iteration), axis=1)\n",
    "        offline_score.append(lgb_model.best_score['valid_0']['kappa'])\n",
    "            \n",
    "\n",
    "        output_preds.append(lgb_model.predict(test[feats], num_iteration=lgb_model.best_iteration))\n",
    "        # feature importance\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = lgb_model.feature_importance(importance_type='gain')\n",
    "        fold_importance_df[\"fold\"] = i + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    print('OOF-MEAN-KAPPA score:%.6f, OOF-STD:%.6f' % (np.mean(offline_score), np.std(offline_score)))\n",
    "    print('feature importance:')\n",
    "    print(feature_importance_df.groupby(['feature'])['importance'].mean().sort_values(ascending=False).head(15))\n",
    "    print('confusion matrix:')\n",
    "    print(confusion_matrix(target, oof_preds))\n",
    "    print('classfication report:')\n",
    "    print(classification_report(target, oof_preds))\n",
    "\n",
    "    return output_preds, oof_probs, np.mean(offline_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current num of features: 362\n",
      "(60934, 362) (15236, 362)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's kappa: 0.482662\n",
      "[200]\tvalid_0's kappa: 0.483023\n",
      "Early stopping, best iteration is:\n",
      "[181]\tvalid_0's kappa: 0.487324\n",
      "(60935, 362) (15235, 362)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's kappa: 0.492389\n",
      "[200]\tvalid_0's kappa: 0.491433\n",
      "[300]\tvalid_0's kappa: 0.489218\n",
      "Early stopping, best iteration is:\n",
      "[250]\tvalid_0's kappa: 0.493711\n",
      "(60937, 362) (15233, 362)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's kappa: 0.491843\n",
      "[200]\tvalid_0's kappa: 0.489416\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's kappa: 0.493458\n",
      "(60937, 362) (15233, 362)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's kappa: 0.479726\n",
      "[200]\tvalid_0's kappa: 0.484878\n",
      "[300]\tvalid_0's kappa: 0.481933\n",
      "Early stopping, best iteration is:\n",
      "[232]\tvalid_0's kappa: 0.485901\n",
      "(60937, 362) (15233, 362)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's kappa: 0.480183\n",
      "[200]\tvalid_0's kappa: 0.481723\n",
      "Early stopping, best iteration is:\n",
      "[174]\tvalid_0's kappa: 0.485272\n",
      "OOF-MEAN-KAPPA score:0.489133, OOF-STD:0.003696\n",
      "feature importance:\n",
      "feature\n",
      "X_sum_5         57121.962857\n",
      "X_sum_2         54574.388222\n",
      "X_sum_4         23580.598815\n",
      "X_sum_min_y     23474.338191\n",
      "C1_min_y        14988.015027\n",
      "C2_min_y        14244.693958\n",
      "C4               9618.940642\n",
      "C5               8846.490017\n",
      "B7_max_y         8688.997093\n",
      "X_sum_skew_y     7038.780734\n",
      "C2               6864.480722\n",
      "I3_x             5501.286123\n",
      "C1_skew_y        4874.198827\n",
      "B7_max_x         4433.783416\n",
      "X3_last_y        3983.332635\n",
      "Name: importance, dtype: float64\n",
      "confusion matrix:\n",
      "[[ 6639  2305  2643]\n",
      " [ 1514  8138  5535]\n",
      " [ 1910  6124 41362]]\n",
      "classfication report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.57      0.61     11587\n",
      "          1       0.49      0.54      0.51     15187\n",
      "          2       0.83      0.84      0.84     49396\n",
      "\n",
      "avg / total       0.74      0.74      0.74     76170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target = train['label'] + 1\n",
    "lgb_preds, lgb_oof, lgb_score = LGB_classfication_model(train, target, test, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        3\n",
       "1        0\n",
       "2        0\n",
       "3        3\n",
       "4        2\n",
       "        ..\n",
       "76165    1\n",
       "76166    1\n",
       "76167    3\n",
       "76168    0\n",
       "76169    1\n",
       "Name: I3_x, Length: 76170, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['I3_x'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    62\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[(train['I3_x'] == 1)&(train['E1']==1)]['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    11\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[(train['I3_x'] == 2)&(train['E1']==1)]['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_no</th>\n",
       "      <th>bef_label</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3_x</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I11</th>\n",
       "      <th>I13</th>\n",
       "      <th>I14</th>\n",
       "      <th>...</th>\n",
       "      <th>E8</th>\n",
       "      <th>E9</th>\n",
       "      <th>E10</th>\n",
       "      <th>E12</th>\n",
       "      <th>E13</th>\n",
       "      <th>E14</th>\n",
       "      <th>E15</th>\n",
       "      <th>E16</th>\n",
       "      <th>E18</th>\n",
       "      <th>event_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0xb2da9bae</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>0xb2da8dd1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>0xb2daa201</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>0xb2da8de8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2829</th>\n",
       "      <td>0xb2da9aee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73847</th>\n",
       "      <td>0xb2da79a1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74661</th>\n",
       "      <td>0xb2da8cdb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75406</th>\n",
       "      <td>0xb2da74d2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75614</th>\n",
       "      <td>0xb2da7e9d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75969</th>\n",
       "      <td>0xb2da99d9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>213 rows × 363 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          cust_no  bef_label  I1   I2  I3_x  I5  I6  I11  I13  I14  ...  E8  \\\n",
       "398    0xb2da9bae        NaN   1  2.0     0   7   0  0.0    2    5  ...   3   \n",
       "479    0xb2da8dd1        NaN   0  6.0     0   0   0  0.0    2    5  ...   3   \n",
       "1436   0xb2daa201        NaN   1  3.0     0   1   0  0.0    4    4  ...   3   \n",
       "1910   0xb2da8de8        NaN   1  7.0     3   0   0  0.0    2    5  ...   3   \n",
       "2829   0xb2da9aee        NaN   1  3.0     0   4   0  0.0    2    5  ...   3   \n",
       "...           ...        ...  ..  ...   ...  ..  ..  ...  ...  ...  ...  ..   \n",
       "73847  0xb2da79a1        NaN   0  5.0     0   0   0  0.0    2    5  ...   3   \n",
       "74661  0xb2da8cdb        NaN   1  4.0     0   7   0  0.0    2    5  ...   3   \n",
       "75406  0xb2da74d2        NaN   1  6.0     0   0   0  0.0    2    5  ...   3   \n",
       "75614  0xb2da7e9d        NaN   0  5.0     0   0   0  0.0    2    5  ...   3   \n",
       "75969  0xb2da99d9        NaN   1  1.0     0   7   0  0.0    2    5  ...   3   \n",
       "\n",
       "       E9  E10  E12  E13  E14      E15  E16  E18  event_num  \n",
       "398     3    1    3    3    1  20000.0    1    1         10  \n",
       "479     3    1    3    3    3      0.0    3    3          7  \n",
       "1436    3    1    3    3    3      0.0    3    3          7  \n",
       "1910    3    1    3    3    3      0.0    3    3          7  \n",
       "2829    3    1    3    3    3      0.0    3    3          7  \n",
       "...    ..  ...  ...  ...  ...      ...  ...  ...        ...  \n",
       "73847   3    1    3    3    3      0.0    3    3          7  \n",
       "74661   3    1    3    3    3      0.0    3    3          6  \n",
       "75406   3    1    3    3    3      0.0    3    3          6  \n",
       "75614   3    1    3    3    1      1.0    1    1         10  \n",
       "75969   3    1    3    3    3      0.0    3    3          7  \n",
       "\n",
       "[213 rows x 363 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[(test['I3_x'] == 1)&(test['E1']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_no</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50701</th>\n",
       "      <td>0xb2da72e0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76562</th>\n",
       "      <td>0xb2daa150</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cust_no  label\n",
       "50701  0xb2da72e0      1\n",
       "76562  0xb2daa150      1"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df[(test['I3_x'] == 2)&(test['E1']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    21556\n",
       "-1     8507\n",
       " 0     7477\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[(train['I3_x'] == 0)]['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current num of features: 309\n",
      "(64488, 309) (16123, 309)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's kappa: 0.540317\n",
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's kappa: 0.542492\n",
      "(64488, 309) (16123, 309)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's kappa: 0.531217\n",
      "[200]\tvalid_0's kappa: 0.532959\n",
      "Early stopping, best iteration is:\n",
      "[148]\tvalid_0's kappa: 0.534663\n",
      "(64488, 309) (16123, 309)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's kappa: 0.552588\n",
      "[200]\tvalid_0's kappa: 0.556367\n",
      "Early stopping, best iteration is:\n",
      "[196]\tvalid_0's kappa: 0.557441\n",
      "(64489, 309) (16122, 309)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's kappa: 0.529648\n",
      "[200]\tvalid_0's kappa: 0.528668\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's kappa: 0.531503\n",
      "(64491, 309) (16120, 309)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's kappa: 0.531798\n",
      "[200]\tvalid_0's kappa: 0.530519\n",
      "Early stopping, best iteration is:\n",
      "[128]\tvalid_0's kappa: 0.53327\n",
      "OOF-MEAN-KAPPA score:0.539874, OOF-STD:0.009553\n",
      "feature importance:\n",
      "feature\n",
      "X_sum_2          130073.052060\n",
      "X_sum_5           58944.742240\n",
      "X_sum_4           26227.204354\n",
      "C2                18642.803890\n",
      "C1_min_y          17351.811281\n",
      "C2_min_y          11490.830560\n",
      "C5                11119.777053\n",
      "B7_max_y          10980.224083\n",
      "C4                 9934.582218\n",
      "I3_x               9848.564312\n",
      "B6_hour_max_y      9809.872783\n",
      "X_sum_skew_y       8141.691269\n",
      "B6_gap_max_x       5452.288903\n",
      "bef_label          4975.843569\n",
      "X_sum_std_y        4381.184059\n",
      "Name: importance, dtype: float64\n",
      "confusion matrix:\n",
      "[[10683  2319  2652]\n",
      " [ 1516  8156  5516]\n",
      " [ 2106  6151 41512]]\n",
      "classfication report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.68      0.71     15654\n",
      "          1       0.49      0.54      0.51     15188\n",
      "          2       0.84      0.83      0.83     49769\n",
      "\n",
      "avg / total       0.75      0.75      0.75     80611\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target = train['label'] + 1\n",
    "lgb_preds, lgb_oof, lgb_score = LGB_classfication_model(train, target, test, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# lgb1 = pd.read_csv(\"lgb1.csv\")\n",
    "# lgb2 = pd.read_csv(\"lgb2.csv\")\n",
    "# lgb3 = pd.read_csv(\"lgb3.csv\")\n",
    "# lgb4 = pd.read_csv(\"lgb4.csv\")\n",
    "# lgb5 = pd.read_csv(\"lgb5.csv\")\n",
    "# lgb6 = pd.read_csv(\"lgb6.csv\")\n",
    "# lgb7 = pd.read_csv(\"lgb7.csv\")\n",
    "# lgb8 = pd.read_csv(\"lgb8.csv\")\n",
    "# lgb9 = pd.read_csv(\"lgb9.csv\")\n",
    "# lgb10 = pd.read_csv(\"lgb10.csv\")\n",
    "# lgb11 = pd.read_csv(\"lgb11.csv\")\n",
    "# lgb13 = pd.read_csv(\"lgb13.csv\")\n",
    "# lgb14 = pd.read_csv(\"lgb14.csv\")\n",
    "# lgb21 = pd.read_csv(\"lgb21.csv\")\n",
    "# lgb22 = pd.read_csv(\"lgb22.csv\")\n",
    "# lgb23 = pd.read_csv(\"lgb23.csv\")\n",
    "# lgb24 = pd.read_csv(\"lgb24.csv\")\n",
    "# lgb24 = pd.read_csv(\"lgb24.csv\")\n",
    "lgb_485 = pd.read_csv(\"lgb26_prab.csv\")\n",
    "cnn_445 = pd.read_csv(\"prediction_cnn_0445.csv\")\n",
    "xgb_1 = pd.read_csv(\"xgb_1.csv\")\n",
    "xgb_1_prab = pd.read_csv(\"xgb_1_prab.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_no</th>\n",
       "      <th>label</th>\n",
       "      <th>prba1</th>\n",
       "      <th>prba2</th>\n",
       "      <th>prba3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x3b9b4615</td>\n",
       "      <td>1</td>\n",
       "      <td>0.064529</td>\n",
       "      <td>0.426921</td>\n",
       "      <td>0.508550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x3b9ae61b</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023218</td>\n",
       "      <td>0.114226</td>\n",
       "      <td>0.862556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x3b9add69</td>\n",
       "      <td>1</td>\n",
       "      <td>0.044682</td>\n",
       "      <td>0.194048</td>\n",
       "      <td>0.761270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x3b9b3601</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014320</td>\n",
       "      <td>0.724767</td>\n",
       "      <td>0.260913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x3b9b2599</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013054</td>\n",
       "      <td>0.508893</td>\n",
       "      <td>0.478053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76717</th>\n",
       "      <td>0xb2d69017</td>\n",
       "      <td>1</td>\n",
       "      <td>0.119785</td>\n",
       "      <td>0.265532</td>\n",
       "      <td>0.614684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76718</th>\n",
       "      <td>0xb2d68153</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010656</td>\n",
       "      <td>0.163321</td>\n",
       "      <td>0.826024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76719</th>\n",
       "      <td>0xb2d5bba1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.073333</td>\n",
       "      <td>0.206951</td>\n",
       "      <td>0.719716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76720</th>\n",
       "      <td>0xb2d61b9b</td>\n",
       "      <td>1</td>\n",
       "      <td>0.056048</td>\n",
       "      <td>0.134226</td>\n",
       "      <td>0.809726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76721</th>\n",
       "      <td>0xb2d70079</td>\n",
       "      <td>0</td>\n",
       "      <td>0.149579</td>\n",
       "      <td>0.599429</td>\n",
       "      <td>0.250992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76722 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          cust_no  label     prba1     prba2     prba3\n",
       "0      0x3b9b4615      1  0.064529  0.426921  0.508550\n",
       "1      0x3b9ae61b      1  0.023218  0.114226  0.862556\n",
       "2      0x3b9add69      1  0.044682  0.194048  0.761270\n",
       "3      0x3b9b3601      0  0.014320  0.724767  0.260913\n",
       "4      0x3b9b2599      0  0.013054  0.508893  0.478053\n",
       "...           ...    ...       ...       ...       ...\n",
       "76717  0xb2d69017      1  0.119785  0.265532  0.614684\n",
       "76718  0xb2d68153      1  0.010656  0.163321  0.826024\n",
       "76719  0xb2d5bba1      1  0.073333  0.206951  0.719716\n",
       "76720  0xb2d61b9b      1  0.056048  0.134226  0.809726\n",
       "76721  0xb2d70079      0  0.149579  0.599429  0.250992\n",
       "\n",
       "[76722 rows x 5 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_485"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.06945424, 0.44883579, 0.48170997],\n",
       "       [0.02966919, 0.13753896, 0.83279184],\n",
       "       [0.05742764, 0.22992203, 0.71265032],\n",
       "       ...,\n",
       "       [0.06750677, 0.20759096, 0.72490226],\n",
       "       [0.06739202, 0.13232507, 0.8002829 ],\n",
       "       [0.15136426, 0.56719672, 0.28143901]])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76722"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lgb_485['cust_no']==cnn_445['cust_no']).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_no</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x3b9b4615</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x3b9ae61b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x3b9add69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x3b9b3601</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x3b9b2599</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76717</th>\n",
       "      <td>0xb2d69017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76718</th>\n",
       "      <td>0xb2d68153</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76719</th>\n",
       "      <td>0xb2d5bba1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76720</th>\n",
       "      <td>0xb2d61b9b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76721</th>\n",
       "      <td>0xb2d70079</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76722 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          cust_no  label\n",
       "0      0x3b9b4615      1\n",
       "1      0x3b9ae61b      1\n",
       "2      0x3b9add69      1\n",
       "3      0x3b9b3601      0\n",
       "4      0x3b9b2599      1\n",
       "...           ...    ...\n",
       "76717  0xb2d69017      1\n",
       "76718  0xb2d68153      1\n",
       "76719  0xb2d5bba1      1\n",
       "76720  0xb2d61b9b      1\n",
       "76721  0xb2d70079      0\n",
       "\n",
       "[76722 rows x 2 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_1 = pd.DataFrame(cnn_445['cust_no'])\n",
    "ensemble_1['label'] =  np.argmax((0.75*lgb_485[['prba1', 'prba2', 'prba3']].values + 0.25*cnn_445[['pred_-1', 'pred_0', 'pred_1']].values), axis=1) - 1\n",
    "ensemble_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_no</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x3b9b4615</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x3b9ae61b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x3b9add69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x3b9b3601</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x3b9b2599</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76717</th>\n",
       "      <td>0xb2d69017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76718</th>\n",
       "      <td>0xb2d68153</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76719</th>\n",
       "      <td>0xb2d5bba1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76720</th>\n",
       "      <td>0xb2d61b9b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76721</th>\n",
       "      <td>0xb2d70079</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76722 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          cust_no  label\n",
       "0      0x3b9b4615      1\n",
       "1      0x3b9ae61b      1\n",
       "2      0x3b9add69      1\n",
       "3      0x3b9b3601      0\n",
       "4      0x3b9b2599      1\n",
       "...           ...    ...\n",
       "76717  0xb2d69017      1\n",
       "76718  0xb2d68153      1\n",
       "76719  0xb2d5bba1      1\n",
       "76720  0xb2d61b9b      1\n",
       "76721  0xb2d70079      0\n",
       "\n",
       "[76722 rows x 2 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_1.to_csv('ensemble_1.csv', index=False)\n",
    "ensemble_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    48065\n",
       " 0    15543\n",
       "-1    13114\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cnn_445['label']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    48351\n",
       " 0    18130\n",
       "-1    10241\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lgb_485['label']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     65440\n",
       "False    11282\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cnn_445['label']==lgb_485['label']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     74451\n",
       "False     2271\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "(ensemble_1['label']==lgb_485['label']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     67623\n",
       "False     9099\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "(ensemble_1['label']==cnn_445['label']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     73813\n",
       "False     2909\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lgb26['label']==lgb22['label']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     73813\n",
       "False     2909\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lgb26['label']==lgb22['label']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import catboost as cat\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=2020)\n",
    "oof = np.zeros([len(x_train), 7])\n",
    "predictions = np.zeros(test_data.shape[0])  \n",
    "\n",
    "for fold_, (train_index, test_index) in enumerate(folds.split(x_train, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_ + 1))\n",
    "    train_x, test_x, train_y, test_y = x_train.iloc[train_index], x_train.iloc[test_index], y_train.iloc[\n",
    "        train_index], y_train.iloc[test_index]\n",
    "\n",
    "    cbt_model = cat.CatBoostClassifier(iterations=2500, learning_rate=0.057, max_depth=7, l2_leaf_reg=2, verbose=100,\n",
    "                                       early_stopping_rounds=50,eval_metric='MAE',cat_features=L, loss_function='MultiClass',\n",
    "                                     )\n",
    "    cbt_model.fit(train_x, train_y, eval_set=(test_x, test_y))\n",
    "    predictions += cbt_model.predict(test_data)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost as cat\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = cohen_kappa_score(np.array([1,0.5]), np.array([1,1]))\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0], dtype=int64)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " np.argmax(np.array([[1,0],[2,1]]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "def histogram(ratings, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Returns the counts of each type of rating that a rater made\n",
    "    \"\"\"\n",
    "    if min_rating is None:\n",
    "        min_rating = min(ratings)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(ratings)\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    hist_ratings = [0 for x in range(num_ratings)]\n",
    "    for r in ratings:\n",
    "        hist_ratings[r - min_rating] += 1\n",
    "    return hist_ratings\n",
    " \n",
    "def quadratic_weighted_kappa(rater_a, rater_b, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Calculates the quadratic weighted kappa\n",
    "    quadratic_weighted_kappa calculates the quadratic weighted kappa\n",
    "    value, which is a measure of inter-rater agreement between two raters\n",
    "    that provide discrete numeric ratings.  Potential values range from -1\n",
    "    (representing complete disagreement) to 1 (representing complete\n",
    "    agreement).  A kappa value of 0 is expected if all agreement is due to\n",
    "    chance.\n",
    "    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n",
    "    each correspond to a list of integer ratings.  These lists must have the\n",
    "    same length.\n",
    "    The ratings should be integers, and it is assumed that they contain\n",
    "    the complete range of possible ratings.\n",
    "    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n",
    "    is the minimum possible rating, and max_rating is the maximum possible\n",
    "    rating\n",
    "    \"\"\"\n",
    "    rater_a = np.array(rater_a, dtype=int)\n",
    "    rater_b = np.array(rater_b, dtype=int)\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(min(rater_a), min(rater_b))\n",
    "    if max_rating is None:\n",
    "        max_rating = max(max(rater_a), max(rater_b))\n",
    "    conf_mat = confusion_matrix(rater_a, rater_b,\n",
    "                                min_rating, max_rating)\n",
    " \n",
    "    num_ratings = len(conf_mat)\n",
    "    num_scored_items = float(len(rater_a))\n",
    " \n",
    "    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n",
    " \n",
    "    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n",
    " \n",
    "    numerator = 0.0\n",
    "    denominator = 0.0\n",
    " \n",
    "    for i in range(num_ratings):\n",
    "        for j in range(num_ratings):\n",
    "            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n",
    "                              / num_scored_items)\n",
    "            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n",
    "            numerator += d * conf_mat[i][j] / num_scored_items\n",
    "            denominator += d * expected_count / num_scored_items\n",
    " \n",
    "    return 1.0 - numerator / denominator\n",
    "\n",
    "def buildHistMat(preds, label):\n",
    "    #get round preds and number of classes\n",
    "    preds = np.round(preds)\n",
    "    num_classes = len(np.unique(label))\n",
    "\n",
    "    #build histogram matrix\n",
    "    histMat = np.zeros((num_classes, num_classes))\n",
    "    for i in range(num_classes):\n",
    "        for j in range(num_classes):\n",
    "            histMat[i,j] = np.sum(((preds==i+1)*(label==j+1)))\n",
    "\n",
    "    histMat = histMat.astype(int)\n",
    "    return histMat\n",
    "\n",
    "\n",
    "# def kappaScore(preds, dtrain):\n",
    "#     #retruning a negative score because xgb is minimizing what we want to maximise :)\n",
    "#     label = np.array(dtrain.get_label())\n",
    "#     label = label.astype(int)\n",
    "#     preds = np.array(preds)\n",
    "#     preds = np.clip(np.round(preds), np.min(label), np.max(label)).astype(int)\n",
    "#     kappa = quadratic_weighted_kappa(preds, label)\n",
    "#     return '-kappa', -kappa\n",
    "\n",
    "def kappaScore(preds, dtrain):\n",
    "    y_true = np.array(dtrain.get_label())\n",
    "    \n",
    "#     print(y_true[:10], preds[:10])\n",
    "#     print(y_true.shape, preds.shape)\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "#     preds = np.argmax(preds.reshape(3, -1), axis=0)\n",
    "    score = cohen_kappa_score(y_true, preds)\n",
    "    return '-kappa', -score\n",
    "\n",
    "def customObj(preds, dtrain):\n",
    "    #get labels\n",
    "    label = dtrain.get_label().astype(int)\n",
    "\n",
    "    #clip round & clip predictions\n",
    "    preds = np.clip(np.round(preds), np.min(label), np.max(label)).astype(int)\n",
    "\n",
    "    #convert prediction into index starting at 0 (for Histogram Matrix)\n",
    "    idx = np.array(preds.astype(int)-1)\n",
    "\n",
    "    #build histogram matrix\n",
    "    histMat = buildHistMat(preds, label)\n",
    "\n",
    "    #return a \"kappa-weighted\" squared error grad & a constant hess\n",
    "    grad = histMat[idx, (label-1)]*(idx-(label-1))\n",
    "    hess = np.ones(shape=preds.shape)\n",
    "    return grad, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def XGB_classfication_model(train, target, test, k):\n",
    "    feats = [f for f in train.columns if f not in ['cust_no', 'label', 'weight']]\n",
    "    print('Current num of features:', len(feats))\n",
    "    folds = StratifiedKFold(n_splits=k, shuffle=True, random_state=2020)\n",
    "    oof_preds = np.zeros(train.shape[0])\n",
    "    oof_probs = np.zeros((train.shape[0], 3))\n",
    "    output_preds = []\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    offline_score = []\n",
    "    for i, (train_index, test_index) in enumerate(folds.split(train, target)):\n",
    "        train_y, test_y = target[train_index], target[test_index]\n",
    "        train_X, test_X = train[feats].iloc[train_index, :], train[feats].iloc[test_index, :]\n",
    "        train_weight, valid_weight = train['weight'][train_index], train['weight'][test_index]\n",
    "        print(train_X.shape, test_X.shape)\n",
    "#         dtrain = lgb.Dataset(train_X,\n",
    "#                              label=train_y,\n",
    "#                              categorical_feature=cate_cols, \n",
    "#                              weight=train_weight.values.flatten(order='F'),\n",
    "#                             )\n",
    "#         dval = lgb.Dataset(test_X,\n",
    "#                            label=test_y,\n",
    "#                           categorical_feature=cate_cols, )\n",
    "\n",
    "        dtrain = xgb.DMatrix(train_X, label=train_y, weight=train_weight.values.flatten(order='F'))\n",
    "        dval = xgb.DMatrix(test_X, label=test_y)\n",
    "        watchlist = [(dtrain, 'train'),(dval, 'valid')]\n",
    "        \n",
    "        param = {\n",
    "        'eta': 0.05,\n",
    "        'max_depth': 8,\n",
    "#         'objective':'multi:softmax',# 多分类的问题\n",
    "         'objective': 'multi:softprob',# 多分类的问题\n",
    "        'booster':'gbtree',\n",
    "        'num_class':3,# 类别数，与 multisoftmax 并用\n",
    "        'n_jobs':20,\n",
    "        'gamma':0.2,# 用于控制是否后剪枝的参数,越大越保守\n",
    "        'min_child_weight':1,\n",
    "        'subsample':0.7,# 随机采样训练样本\n",
    "        'colsample_bytree':0.7,\n",
    "        'seed':2021# 随机种子\n",
    "\n",
    "        }\n",
    "    \n",
    "        xgb_model = xgb.train(\n",
    "            param, \n",
    "            dtrain, \n",
    "            num_boost_round =100, \n",
    "            evals = watchlist,\n",
    "#             obj=customObj, \n",
    "            feval=kappaScore, \n",
    "            verbose_eval=True, \n",
    "            early_stopping_rounds=5)\n",
    "\n",
    "        oof_probs[test_index] = xgb_model.predict((xgb.DMatrix(test_X[feats])))\n",
    "        oof_preds[test_index] = np.argmax(oof_probs[test_index], axis=1)\n",
    "#         offline_score.append(xgb_model.best_score['valid_0']['kappa'])\n",
    "            \n",
    "\n",
    "        output_preds.append(xgb_model.predict(xgb.DMatrix(test[feats])))\n",
    "        # feature importance\n",
    "#         fold_importance_df = pd.DataFrame()\n",
    "#         fold_importance_df[\"feature\"] = feats\n",
    "#         fold_importance_df[\"importance\"] = xgb_model.feature_importance(importance_type='gain')\n",
    "#         fold_importance_df[\"fold\"] = i + 1\n",
    "#         feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "#     print('OOF-MEAN-KAPPA score:%.6f, OOF-STD:%.6f' % (np.mean(offline_score), np.std(offline_score)))\n",
    "#     print('feature importance:')\n",
    "#     print(feature_importance_df.groupby(['feature'])['importance'].mean().sort_values(ascending=False).head(15))\n",
    "#     print('confusion matrix:')\n",
    "    print(target[:2], oof_preds[:2], target.shape, oof_preds.shape)\n",
    "    print(confusion_matrix(target, oof_preds))\n",
    "    print('classfication report:')\n",
    "    print(classification_report(target, oof_preds))\n",
    "\n",
    "    return output_preds, oof_probs, np.mean(offline_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current num of features: 362\n",
      "(60934, 362) (15236, 362)\n",
      "[0]\ttrain-merror:0.300354\tvalid-merror:0.294303\ttrain--kappa:-0.487816\tvalid--kappa:-0.434192\n",
      "Multiple eval metrics have been passed: 'valid--kappa' will be used for early stopping.\n",
      "\n",
      "Will train until valid--kappa hasn't improved in 5 rounds.\n",
      "[1]\ttrain-merror:0.29118\tvalid-merror:0.285377\ttrain--kappa:-0.503275\tvalid--kappa:-0.448615\n",
      "[2]\ttrain-merror:0.287542\tvalid-merror:0.280192\ttrain--kappa:-0.509639\tvalid--kappa:-0.453382\n",
      "[3]\ttrain-merror:0.286531\tvalid-merror:0.279142\ttrain--kappa:-0.511321\tvalid--kappa:-0.456203\n",
      "[4]\ttrain-merror:0.283694\tvalid-merror:0.277369\ttrain--kappa:-0.516096\tvalid--kappa:-0.458485\n",
      "[5]\ttrain-merror:0.283383\tvalid-merror:0.277304\ttrain--kappa:-0.516527\tvalid--kappa:-0.459902\n",
      "[6]\ttrain-merror:0.281775\tvalid-merror:0.275466\ttrain--kappa:-0.51949\tvalid--kappa:-0.4626\n",
      "[7]\ttrain-merror:0.279652\tvalid-merror:0.27481\ttrain--kappa:-0.522975\tvalid--kappa:-0.463686\n",
      "[8]\ttrain-merror:0.27897\tvalid-merror:0.274678\ttrain--kappa:-0.524143\tvalid--kappa:-0.463584\n",
      "[9]\ttrain-merror:0.278493\tvalid-merror:0.275138\ttrain--kappa:-0.525023\tvalid--kappa:-0.462954\n",
      "[10]\ttrain-merror:0.277541\tvalid-merror:0.274416\ttrain--kappa:-0.526715\tvalid--kappa:-0.464034\n",
      "[11]\ttrain-merror:0.276945\tvalid-merror:0.27376\ttrain--kappa:-0.527671\tvalid--kappa:-0.465233\n",
      "[12]\ttrain-merror:0.276161\tvalid-merror:0.27376\ttrain--kappa:-0.529144\tvalid--kappa:-0.464776\n",
      "[13]\ttrain-merror:0.275621\tvalid-merror:0.274941\ttrain--kappa:-0.530141\tvalid--kappa:-0.462433\n",
      "[14]\ttrain-merror:0.274565\tvalid-merror:0.27435\ttrain--kappa:-0.53187\tvalid--kappa:-0.463514\n",
      "[15]\ttrain-merror:0.273769\tvalid-merror:0.274285\ttrain--kappa:-0.533183\tvalid--kappa:-0.464436\n",
      "[16]\ttrain-merror:0.272965\tvalid-merror:0.273891\ttrain--kappa:-0.53459\tvalid--kappa:-0.464832\n",
      "Stopping. Best iteration:\n",
      "[11]\ttrain-merror:0.276945\tvalid-merror:0.27376\ttrain--kappa:-0.527671\tvalid--kappa:-0.465233\n",
      "\n",
      "(60935, 362) (15235, 362)\n",
      "[0]\ttrain-merror:0.301039\tvalid-merror:0.283623\ttrain--kappa:-0.488545\tvalid--kappa:-0.446269\n",
      "Multiple eval metrics have been passed: 'valid--kappa' will be used for early stopping.\n",
      "\n",
      "Will train until valid--kappa hasn't improved in 5 rounds.\n",
      "[1]\ttrain-merror:0.28917\tvalid-merror:0.277453\ttrain--kappa:-0.50747\tvalid--kappa:-0.463393\n",
      "[2]\ttrain-merror:0.285366\tvalid-merror:0.275025\ttrain--kappa:-0.513707\tvalid--kappa:-0.466849\n",
      "[3]\ttrain-merror:0.283823\tvalid-merror:0.274171\ttrain--kappa:-0.516328\tvalid--kappa:-0.466338\n",
      "[4]\ttrain-merror:0.283326\tvalid-merror:0.273515\ttrain--kappa:-0.517272\tvalid--kappa:-0.468018\n",
      "[5]\ttrain-merror:0.28266\tvalid-merror:0.273515\ttrain--kappa:-0.518214\tvalid--kappa:-0.466729\n",
      "[6]\ttrain-merror:0.281057\tvalid-merror:0.273843\ttrain--kappa:-0.520921\tvalid--kappa:-0.466386\n",
      "[7]\ttrain-merror:0.280021\tvalid-merror:0.272924\ttrain--kappa:-0.522567\tvalid--kappa:-0.467542\n",
      "[8]\ttrain-merror:0.278952\tvalid-merror:0.271349\ttrain--kappa:-0.524374\tvalid--kappa:-0.470563\n",
      "[9]\ttrain-merror:0.27832\tvalid-merror:0.270889\ttrain--kappa:-0.525423\tvalid--kappa:-0.471738\n",
      "[10]\ttrain-merror:0.277677\tvalid-merror:0.26997\ttrain--kappa:-0.526403\tvalid--kappa:-0.473612\n",
      "[11]\ttrain-merror:0.276876\tvalid-merror:0.270824\ttrain--kappa:-0.527584\tvalid--kappa:-0.472539\n",
      "[12]\ttrain-merror:0.276417\tvalid-merror:0.269445\ttrain--kappa:-0.528376\tvalid--kappa:-0.474974\n",
      "[13]\ttrain-merror:0.275161\tvalid-merror:0.269248\ttrain--kappa:-0.530537\tvalid--kappa:-0.475675\n",
      "[14]\ttrain-merror:0.2753\tvalid-merror:0.267804\ttrain--kappa:-0.530246\tvalid--kappa:-0.478556\n",
      "[15]\ttrain-merror:0.274451\tvalid-merror:0.267804\ttrain--kappa:-0.531866\tvalid--kappa:-0.478796\n",
      "[16]\ttrain-merror:0.273609\tvalid-merror:0.268658\ttrain--kappa:-0.533105\tvalid--kappa:-0.477342\n",
      "[17]\ttrain-merror:0.273002\tvalid-merror:0.268198\ttrain--kappa:-0.534177\tvalid--kappa:-0.478195\n",
      "[18]\ttrain-merror:0.272352\tvalid-merror:0.26833\ttrain--kappa:-0.535259\tvalid--kappa:-0.477663\n",
      "[19]\ttrain-merror:0.272147\tvalid-merror:0.268067\ttrain--kappa:-0.535563\tvalid--kappa:-0.478529\n",
      "[20]\ttrain-merror:0.271092\tvalid-merror:0.267936\ttrain--kappa:-0.537297\tvalid--kappa:-0.478724\n",
      "Stopping. Best iteration:\n",
      "[15]\ttrain-merror:0.274451\tvalid-merror:0.267804\ttrain--kappa:-0.531866\tvalid--kappa:-0.478796\n",
      "\n",
      "(60937, 362) (15233, 362)\n",
      "[0]\ttrain-merror:0.303499\tvalid-merror:0.283398\ttrain--kappa:-0.483166\tvalid--kappa:-0.446482\n",
      "Multiple eval metrics have been passed: 'valid--kappa' will be used for early stopping.\n",
      "\n",
      "Will train until valid--kappa hasn't improved in 5 rounds.\n",
      "[1]\ttrain-merror:0.292732\tvalid-merror:0.276308\ttrain--kappa:-0.501481\tvalid--kappa:-0.461912\n",
      "[2]\ttrain-merror:0.288682\tvalid-merror:0.273354\ttrain--kappa:-0.508317\tvalid--kappa:-0.465999\n",
      "[3]\ttrain-merror:0.286969\tvalid-merror:0.273354\ttrain--kappa:-0.51088\tvalid--kappa:-0.46689\n",
      "[4]\ttrain-merror:0.285258\tvalid-merror:0.27145\ttrain--kappa:-0.513629\tvalid--kappa:-0.469729\n",
      "[5]\ttrain-merror:0.284028\tvalid-merror:0.270137\ttrain--kappa:-0.515838\tvalid--kappa:-0.472798\n",
      "[6]\ttrain-merror:0.28415\tvalid-merror:0.271122\ttrain--kappa:-0.515585\tvalid--kappa:-0.470698\n",
      "[7]\ttrain-merror:0.282377\tvalid-merror:0.272238\ttrain--kappa:-0.518444\tvalid--kappa:-0.467705\n",
      "[8]\ttrain-merror:0.281843\tvalid-merror:0.270925\ttrain--kappa:-0.518927\tvalid--kappa:-0.470052\n",
      "[9]\ttrain-merror:0.280114\tvalid-merror:0.270531\ttrain--kappa:-0.522126\tvalid--kappa:-0.471228\n",
      "[10]\ttrain-merror:0.278553\tvalid-merror:0.269087\ttrain--kappa:-0.524881\tvalid--kappa:-0.474502\n",
      "[11]\ttrain-merror:0.278041\tvalid-merror:0.269546\ttrain--kappa:-0.52582\tvalid--kappa:-0.47397\n",
      "[12]\ttrain-merror:0.277755\tvalid-merror:0.269678\ttrain--kappa:-0.526417\tvalid--kappa:-0.473556\n",
      "[13]\ttrain-merror:0.276844\tvalid-merror:0.269612\ttrain--kappa:-0.527916\tvalid--kappa:-0.474259\n",
      "[14]\ttrain-merror:0.276238\tvalid-merror:0.268299\ttrain--kappa:-0.528999\tvalid--kappa:-0.476615\n",
      "[15]\ttrain-merror:0.275776\tvalid-merror:0.268299\ttrain--kappa:-0.529713\tvalid--kappa:-0.476892\n",
      "[16]\ttrain-merror:0.274875\tvalid-merror:0.268299\ttrain--kappa:-0.531395\tvalid--kappa:-0.476952\n",
      "[17]\ttrain-merror:0.273635\tvalid-merror:0.267708\ttrain--kappa:-0.533496\tvalid--kappa:-0.478132\n",
      "[18]\ttrain-merror:0.273148\tvalid-merror:0.267577\ttrain--kappa:-0.534337\tvalid--kappa:-0.477916\n",
      "[19]\ttrain-merror:0.272675\tvalid-merror:0.267052\ttrain--kappa:-0.535086\tvalid--kappa:-0.479117\n",
      "[20]\ttrain-merror:0.272268\tvalid-merror:0.267314\ttrain--kappa:-0.535789\tvalid--kappa:-0.478169\n",
      "[21]\ttrain-merror:0.271609\tvalid-merror:0.26738\ttrain--kappa:-0.5369\tvalid--kappa:-0.478707\n",
      "[22]\ttrain-merror:0.270523\tvalid-merror:0.266986\ttrain--kappa:-0.538911\tvalid--kappa:-0.479179\n",
      "[23]\ttrain-merror:0.269246\tvalid-merror:0.267708\ttrain--kappa:-0.541066\tvalid--kappa:-0.478194\n",
      "[24]\ttrain-merror:0.268942\tvalid-merror:0.266789\ttrain--kappa:-0.541657\tvalid--kappa:-0.479837\n",
      "[25]\ttrain-merror:0.268087\tvalid-merror:0.266724\ttrain--kappa:-0.543138\tvalid--kappa:-0.480009\n",
      "[26]\ttrain-merror:0.266998\tvalid-merror:0.266461\ttrain--kappa:-0.544967\tvalid--kappa:-0.480842\n",
      "[27]\ttrain-merror:0.266295\tvalid-merror:0.266133\ttrain--kappa:-0.546159\tvalid--kappa:-0.481414\n",
      "[28]\ttrain-merror:0.265879\tvalid-merror:0.26633\ttrain--kappa:-0.546929\tvalid--kappa:-0.480736\n",
      "[29]\ttrain-merror:0.264913\tvalid-merror:0.266527\ttrain--kappa:-0.548601\tvalid--kappa:-0.480113\n",
      "[30]\ttrain-merror:0.264062\tvalid-merror:0.266264\ttrain--kappa:-0.55001\tvalid--kappa:-0.481131\n",
      "[31]\ttrain-merror:0.262983\tvalid-merror:0.265739\ttrain--kappa:-0.551749\tvalid--kappa:-0.482028\n",
      "[32]\ttrain-merror:0.262429\tvalid-merror:0.265936\ttrain--kappa:-0.552751\tvalid--kappa:-0.481823\n",
      "[33]\ttrain-merror:0.261987\tvalid-merror:0.265608\ttrain--kappa:-0.553529\tvalid--kappa:-0.482251\n",
      "[34]\ttrain-merror:0.261374\tvalid-merror:0.265804\ttrain--kappa:-0.554552\tvalid--kappa:-0.481657\n",
      "[35]\ttrain-merror:0.260705\tvalid-merror:0.265017\ttrain--kappa:-0.555661\tvalid--kappa:-0.483252\n",
      "[36]\ttrain-merror:0.260485\tvalid-merror:0.265214\ttrain--kappa:-0.556172\tvalid--kappa:-0.482782\n",
      "[37]\ttrain-merror:0.259142\tvalid-merror:0.265279\ttrain--kappa:-0.558411\tvalid--kappa:-0.482513\n",
      "[38]\ttrain-merror:0.258552\tvalid-merror:0.264754\ttrain--kappa:-0.559421\tvalid--kappa:-0.483482\n",
      "[39]\ttrain-merror:0.257622\tvalid-merror:0.264623\ttrain--kappa:-0.560928\tvalid--kappa:-0.483856\n",
      "[40]\ttrain-merror:0.257145\tvalid-merror:0.263901\ttrain--kappa:-0.561743\tvalid--kappa:-0.48533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41]\ttrain-merror:0.256909\tvalid-merror:0.264163\ttrain--kappa:-0.562139\tvalid--kappa:-0.485124\n",
      "[42]\ttrain-merror:0.256095\tvalid-merror:0.264623\ttrain--kappa:-0.563543\tvalid--kappa:-0.484053\n",
      "[43]\ttrain-merror:0.25493\tvalid-merror:0.263901\ttrain--kappa:-0.565519\tvalid--kappa:-0.485218\n",
      "[44]\ttrain-merror:0.254469\tvalid-merror:0.264163\ttrain--kappa:-0.566284\tvalid--kappa:-0.484929\n",
      "[45]\ttrain-merror:0.253831\tvalid-merror:0.264492\ttrain--kappa:-0.567432\tvalid--kappa:-0.48418\n",
      "Stopping. Best iteration:\n",
      "[40]\ttrain-merror:0.257145\tvalid-merror:0.263901\ttrain--kappa:-0.561743\tvalid--kappa:-0.48533\n",
      "\n",
      "(60937, 362) (15233, 362)\n",
      "[0]\ttrain-merror:0.298846\tvalid-merror:0.289503\ttrain--kappa:-0.490188\tvalid--kappa:-0.441172\n",
      "Multiple eval metrics have been passed: 'valid--kappa' will be used for early stopping.\n",
      "\n",
      "Will train until valid--kappa hasn't improved in 5 rounds.\n",
      "[1]\ttrain-merror:0.291264\tvalid-merror:0.280706\ttrain--kappa:-0.503596\tvalid--kappa:-0.453092\n",
      "[2]\ttrain-merror:0.287444\tvalid-merror:0.278934\ttrain--kappa:-0.510038\tvalid--kappa:-0.455684\n",
      "[3]\ttrain-merror:0.287118\tvalid-merror:0.278343\ttrain--kappa:-0.510533\tvalid--kappa:-0.458382\n",
      "[4]\ttrain-merror:0.285292\tvalid-merror:0.27808\ttrain--kappa:-0.513589\tvalid--kappa:-0.458383\n",
      "[5]\ttrain-merror:0.283688\tvalid-merror:0.276439\ttrain--kappa:-0.516319\tvalid--kappa:-0.462324\n",
      "[6]\ttrain-merror:0.282395\tvalid-merror:0.276045\ttrain--kappa:-0.51834\tvalid--kappa:-0.463385\n",
      "[7]\ttrain-merror:0.280771\tvalid-merror:0.276308\ttrain--kappa:-0.520916\tvalid--kappa:-0.462466\n",
      "[8]\ttrain-merror:0.279745\tvalid-merror:0.276768\ttrain--kappa:-0.522642\tvalid--kappa:-0.461927\n",
      "[9]\ttrain-merror:0.278358\tvalid-merror:0.275586\ttrain--kappa:-0.525114\tvalid--kappa:-0.464585\n",
      "[10]\ttrain-merror:0.27724\tvalid-merror:0.275717\ttrain--kappa:-0.526851\tvalid--kappa:-0.464609\n",
      "[11]\ttrain-merror:0.276341\tvalid-merror:0.275061\ttrain--kappa:-0.528563\tvalid--kappa:-0.464931\n",
      "[12]\ttrain-merror:0.274748\tvalid-merror:0.275717\ttrain--kappa:-0.531239\tvalid--kappa:-0.463861\n",
      "[13]\ttrain-merror:0.274887\tvalid-merror:0.275061\ttrain--kappa:-0.530994\tvalid--kappa:-0.464556\n",
      "[14]\ttrain-merror:0.273664\tvalid-merror:0.27447\ttrain--kappa:-0.533175\tvalid--kappa:-0.465677\n",
      "[15]\ttrain-merror:0.272206\tvalid-merror:0.273879\ttrain--kappa:-0.535671\tvalid--kappa:-0.466661\n",
      "[16]\ttrain-merror:0.271861\tvalid-merror:0.273223\ttrain--kappa:-0.536149\tvalid--kappa:-0.468203\n",
      "[17]\ttrain-merror:0.270804\tvalid-merror:0.273879\ttrain--kappa:-0.538061\tvalid--kappa:-0.466398\n",
      "[18]\ttrain-merror:0.270398\tvalid-merror:0.27401\ttrain--kappa:-0.538848\tvalid--kappa:-0.466281\n",
      "[19]\ttrain-merror:0.270192\tvalid-merror:0.27342\ttrain--kappa:-0.539125\tvalid--kappa:-0.467411\n",
      "[20]\ttrain-merror:0.269843\tvalid-merror:0.274273\ttrain--kappa:-0.53973\tvalid--kappa:-0.465884\n",
      "[21]\ttrain-merror:0.26856\tvalid-merror:0.273945\ttrain--kappa:-0.541885\tvalid--kappa:-0.466585\n",
      "Stopping. Best iteration:\n",
      "[16]\ttrain-merror:0.271861\tvalid-merror:0.273223\ttrain--kappa:-0.536149\tvalid--kappa:-0.468203\n",
      "\n",
      "(60937, 362) (15233, 362)\n",
      "[0]\ttrain-merror:0.298639\tvalid-merror:0.284645\ttrain--kappa:-0.49076\tvalid--kappa:-0.448686\n",
      "Multiple eval metrics have been passed: 'valid--kappa' will be used for early stopping.\n",
      "\n",
      "Will train until valid--kappa hasn't improved in 5 rounds.\n",
      "[1]\ttrain-merror:0.291835\tvalid-merror:0.283201\ttrain--kappa:-0.502481\tvalid--kappa:-0.449251\n",
      "[2]\ttrain-merror:0.288055\tvalid-merror:0.279459\ttrain--kappa:-0.508904\tvalid--kappa:-0.45523\n",
      "[3]\ttrain-merror:0.286716\tvalid-merror:0.279525\ttrain--kappa:-0.51129\tvalid--kappa:-0.455088\n",
      "[4]\ttrain-merror:0.285051\tvalid-merror:0.278934\ttrain--kappa:-0.513927\tvalid--kappa:-0.457541\n",
      "[5]\ttrain-merror:0.285249\tvalid-merror:0.279459\ttrain--kappa:-0.513775\tvalid--kappa:-0.457065\n",
      "[6]\ttrain-merror:0.285122\tvalid-merror:0.279853\ttrain--kappa:-0.513991\tvalid--kappa:-0.457139\n",
      "[7]\ttrain-merror:0.283334\tvalid-merror:0.279525\ttrain--kappa:-0.516641\tvalid--kappa:-0.45826\n",
      "[8]\ttrain-merror:0.281175\tvalid-merror:0.279853\ttrain--kappa:-0.520105\tvalid--kappa:-0.457623\n",
      "[9]\ttrain-merror:0.279645\tvalid-merror:0.279\ttrain--kappa:-0.522593\tvalid--kappa:-0.45954\n",
      "[10]\ttrain-merror:0.279576\tvalid-merror:0.277293\ttrain--kappa:-0.522854\tvalid--kappa:-0.462872\n",
      "[11]\ttrain-merror:0.278889\tvalid-merror:0.277687\ttrain--kappa:-0.524168\tvalid--kappa:-0.462211\n",
      "[12]\ttrain-merror:0.277072\tvalid-merror:0.277621\ttrain--kappa:-0.527317\tvalid--kappa:-0.462058\n",
      "[13]\ttrain-merror:0.276447\tvalid-merror:0.277884\ttrain--kappa:-0.528457\tvalid--kappa:-0.462012\n",
      "[14]\ttrain-merror:0.275834\tvalid-merror:0.276308\ttrain--kappa:-0.529415\tvalid--kappa:-0.464945\n",
      "[15]\ttrain-merror:0.274555\tvalid-merror:0.274995\ttrain--kappa:-0.531653\tvalid--kappa:-0.4669\n",
      "[16]\ttrain-merror:0.273944\tvalid-merror:0.275126\ttrain--kappa:-0.53268\tvalid--kappa:-0.46707\n",
      "[17]\ttrain-merror:0.271939\tvalid-merror:0.27552\ttrain--kappa:-0.536167\tvalid--kappa:-0.466177\n",
      "[18]\ttrain-merror:0.271132\tvalid-merror:0.275455\ttrain--kappa:-0.537499\tvalid--kappa:-0.46589\n",
      "[19]\ttrain-merror:0.270446\tvalid-merror:0.275126\ttrain--kappa:-0.538671\tvalid--kappa:-0.466429\n",
      "[20]\ttrain-merror:0.270052\tvalid-merror:0.274995\ttrain--kappa:-0.539441\tvalid--kappa:-0.466542\n",
      "[21]\ttrain-merror:0.269089\tvalid-merror:0.274536\ttrain--kappa:-0.540928\tvalid--kappa:-0.46764\n",
      "[22]\ttrain-merror:0.268196\tvalid-merror:0.273616\ttrain--kappa:-0.542536\tvalid--kappa:-0.468799\n",
      "[23]\ttrain-merror:0.267449\tvalid-merror:0.27342\ttrain--kappa:-0.543745\tvalid--kappa:-0.469311\n",
      "[24]\ttrain-merror:0.267027\tvalid-merror:0.273616\ttrain--kappa:-0.544514\tvalid--kappa:-0.469231\n",
      "[25]\ttrain-merror:0.266004\tvalid-merror:0.273551\ttrain--kappa:-0.546331\tvalid--kappa:-0.469431\n",
      "[26]\ttrain-merror:0.265265\tvalid-merror:0.27296\ttrain--kappa:-0.547702\tvalid--kappa:-0.4704\n",
      "[27]\ttrain-merror:0.264632\tvalid-merror:0.272829\ttrain--kappa:-0.548716\tvalid--kappa:-0.470614\n",
      "[28]\ttrain-merror:0.263953\tvalid-merror:0.27296\ttrain--kappa:-0.549953\tvalid--kappa:-0.47047\n",
      "[29]\ttrain-merror:0.263458\tvalid-merror:0.273157\ttrain--kappa:-0.550724\tvalid--kappa:-0.47028\n",
      "[30]\ttrain-merror:0.262675\tvalid-merror:0.27296\ttrain--kappa:-0.55196\tvalid--kappa:-0.47038\n",
      "[31]\ttrain-merror:0.262017\tvalid-merror:0.273223\ttrain--kappa:-0.553284\tvalid--kappa:-0.47007\n",
      "[32]\ttrain-merror:0.261297\tvalid-merror:0.273945\ttrain--kappa:-0.554466\tvalid--kappa:-0.468557\n",
      "Stopping. Best iteration:\n",
      "[27]\ttrain-merror:0.264632\tvalid-merror:0.272829\ttrain--kappa:-0.548716\tvalid--kappa:-0.470614\n",
      "\n",
      "0    2\n",
      "1    2\n",
      "Name: label, dtype: int64 [2. 2.] (76170,) (76170,)\n",
      "[[ 6292  2408  2887]\n",
      " [ 1318  8160  5709]\n",
      " [ 1813  6495 41088]]\n",
      "classfication report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.54      0.60     11587\n",
      "          1       0.48      0.54      0.51     15187\n",
      "          2       0.83      0.83      0.83     49396\n",
      "\n",
      "avg / total       0.73      0.73      0.73     76170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target = train['label'] + 1\n",
    "xgb_preds, xgb_oof, lgb_score = XGB_classfication_model(train, target, test, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bef_label</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3_x</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I11</th>\n",
       "      <th>I13</th>\n",
       "      <th>I14</th>\n",
       "      <th>I16</th>\n",
       "      <th>...</th>\n",
       "      <th>E8</th>\n",
       "      <th>E9</th>\n",
       "      <th>E10</th>\n",
       "      <th>E12</th>\n",
       "      <th>E13</th>\n",
       "      <th>E14</th>\n",
       "      <th>E15</th>\n",
       "      <th>E16</th>\n",
       "      <th>E18</th>\n",
       "      <th>event_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1170000.00</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5219392.44</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>298000.00</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1700000.00</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76717</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>50000.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76718</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76719</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>50000.00</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76720</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>50000.00</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76721</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3399996.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8000000.00</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76722 rows × 362 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bef_label  I1   I2  I3_x  I5  I6        I11  I13  I14  I16  ...  E8  \\\n",
       "0            0.0   0  2.0     3   7   0        0.0    2    5  1.0  ...   3   \n",
       "1            1.0   0  4.0     3   0   1        0.0    2    5  1.0  ...   3   \n",
       "2            0.0   1  7.0     3   0   0        0.0    2    5  1.0  ...   3   \n",
       "3            0.0   0  4.0     3   0   0        0.0    2    5  1.0  ...   3   \n",
       "4            0.0   0  6.0     3   0   0        0.0    2    5  1.0  ...   3   \n",
       "...          ...  ..  ...   ...  ..  ..        ...  ...  ...  ...  ...  ..   \n",
       "76717        0.0   0  1.0     0   5   0        0.0    2    5  0.0  ...   3   \n",
       "76718        1.0   0  6.0     3   7   0        0.0    2    5  1.0  ...   3   \n",
       "76719        1.0   0  5.0     1   0   0        0.0    2    5  1.0  ...   3   \n",
       "76720        1.0   1  7.0     0   3   0        0.0    2    5  0.0  ...   3   \n",
       "76721        0.0   1  4.0     0   5   1  3399996.0    2    5  0.0  ...   3   \n",
       "\n",
       "       E9  E10  E12  E13  E14         E15  E16  E18  event_num  \n",
       "0       3    3    3    3    3  1170000.00    3    3         13  \n",
       "1       3    3    3    3    3  5219392.44    3    3         13  \n",
       "2       3    3    3    3    3        0.00    3    3          6  \n",
       "3       3    3    3    3    1   298000.00    3    3         11  \n",
       "4       3    3    3    3    3  1700000.00    3    3          9  \n",
       "...    ..  ...  ...  ...  ...         ...  ...  ...        ...  \n",
       "76717   3    3    3    3    3    50000.00    2    2         12  \n",
       "76718   3    1    3    3    3        0.00    3    3          4  \n",
       "76719   3    3    3    3    3    50000.00    3    2         11  \n",
       "76720   3    3    3    3    3    50000.00    3    3          9  \n",
       "76721   3    1    3    3    3  8000000.00    3    3          9  \n",
       "\n",
       "[76722 rows x 362 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.2100434 , 0.4403957 , 0.34956092],\n",
       "        [0.18490225, 0.25873026, 0.5563675 ],\n",
       "        [0.20797056, 0.27410734, 0.5179221 ],\n",
       "        ...,\n",
       "        [0.20065783, 0.22644511, 0.5728971 ],\n",
       "        [0.20172484, 0.23121604, 0.5670591 ],\n",
       "        [0.25281537, 0.43034598, 0.31683865]], dtype=float32),\n",
       " array([[0.17670494, 0.46425682, 0.3590383 ],\n",
       "        [0.16864805, 0.22110534, 0.61024666],\n",
       "        [0.18505928, 0.24781138, 0.5671294 ],\n",
       "        ...,\n",
       "        [0.19121239, 0.2235194 , 0.5852682 ],\n",
       "        [0.19120592, 0.21455933, 0.59423476],\n",
       "        [0.2322962 , 0.46891284, 0.2987909 ]], dtype=float32),\n",
       " array([[0.11662882, 0.5135601 , 0.36981103],\n",
       "        [0.08762727, 0.19194531, 0.72042745],\n",
       "        [0.11479064, 0.22645162, 0.65875775],\n",
       "        ...,\n",
       "        [0.10923067, 0.22791663, 0.6628527 ],\n",
       "        [0.11030485, 0.1597722 , 0.72992295],\n",
       "        [0.17216912, 0.5700958 , 0.25773513]], dtype=float32),\n",
       " array([[0.18073107, 0.46815312, 0.3511158 ],\n",
       "        [0.17180707, 0.2312654 , 0.5969275 ],\n",
       "        [0.1824685 , 0.25258473, 0.5649468 ],\n",
       "        ...,\n",
       "        [0.17102252, 0.2372949 , 0.5916826 ],\n",
       "        [0.18618885, 0.20017187, 0.6136393 ],\n",
       "        [0.23759672, 0.48909584, 0.27330747]], dtype=float32),\n",
       " array([[0.15027112, 0.4779838 , 0.3717451 ],\n",
       "        [0.12246321, 0.19516136, 0.68237543],\n",
       "        [0.14932531, 0.2631416 , 0.58753306],\n",
       "        ...,\n",
       "        [0.12677255, 0.20130737, 0.67192006],\n",
       "        [0.13857819, 0.18386272, 0.67755914],\n",
       "        [0.21796028, 0.51187557, 0.27016416]], dtype=float32)]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    0.636141\n",
       " 0    0.237051\n",
       "-1    0.126808\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = test[['cust_no']].copy()\n",
    "sub_df['label'] = np.argmax(np.mean(xgb_preds, axis=0), axis=1) - 1\n",
    "sub_df['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_no</th>\n",
       "      <th>label</th>\n",
       "      <th>prba1</th>\n",
       "      <th>prba2</th>\n",
       "      <th>prba3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x3b9b4615</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166876</td>\n",
       "      <td>0.472870</td>\n",
       "      <td>0.360254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x3b9ae61b</td>\n",
       "      <td>1</td>\n",
       "      <td>0.147090</td>\n",
       "      <td>0.219642</td>\n",
       "      <td>0.633269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x3b9add69</td>\n",
       "      <td>1</td>\n",
       "      <td>0.167923</td>\n",
       "      <td>0.252819</td>\n",
       "      <td>0.579258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x3b9b3601</td>\n",
       "      <td>0</td>\n",
       "      <td>0.141970</td>\n",
       "      <td>0.532822</td>\n",
       "      <td>0.325208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x3b9b2599</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135681</td>\n",
       "      <td>0.445967</td>\n",
       "      <td>0.418352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76717</th>\n",
       "      <td>0xb2d69017</td>\n",
       "      <td>1</td>\n",
       "      <td>0.216991</td>\n",
       "      <td>0.298102</td>\n",
       "      <td>0.484907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76718</th>\n",
       "      <td>0xb2d68153</td>\n",
       "      <td>1</td>\n",
       "      <td>0.128733</td>\n",
       "      <td>0.226702</td>\n",
       "      <td>0.644565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76719</th>\n",
       "      <td>0xb2d5bba1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.159779</td>\n",
       "      <td>0.223297</td>\n",
       "      <td>0.616924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76720</th>\n",
       "      <td>0xb2d61b9b</td>\n",
       "      <td>1</td>\n",
       "      <td>0.165601</td>\n",
       "      <td>0.197916</td>\n",
       "      <td>0.636483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76721</th>\n",
       "      <td>0xb2d70079</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222568</td>\n",
       "      <td>0.494065</td>\n",
       "      <td>0.283367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76722 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          cust_no  label     prba1     prba2     prba3\n",
       "0      0x3b9b4615      0  0.166876  0.472870  0.360254\n",
       "1      0x3b9ae61b      1  0.147090  0.219642  0.633269\n",
       "2      0x3b9add69      1  0.167923  0.252819  0.579258\n",
       "3      0x3b9b3601      0  0.141970  0.532822  0.325208\n",
       "4      0x3b9b2599      0  0.135681  0.445967  0.418352\n",
       "...           ...    ...       ...       ...       ...\n",
       "76717  0xb2d69017      1  0.216991  0.298102  0.484907\n",
       "76718  0xb2d68153      1  0.128733  0.226702  0.644565\n",
       "76719  0xb2d5bba1      1  0.159779  0.223297  0.616924\n",
       "76720  0xb2d61b9b      1  0.165601  0.197916  0.636483\n",
       "76721  0xb2d70079      0  0.222568  0.494065  0.283367\n",
       "\n",
       "[76722 rows x 5 columns]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df[['prba1', 'prba2', 'prba3']] = np.mean(xgb_preds, axis=0)\n",
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv('xgb_1_prab.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv('xgb_1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     72478\n",
       "False     4244\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ensemble_1['label']==xgb_1['label']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     73202\n",
       "False     3520\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lgb_485['label']==xgb_1['label']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_no</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x3b9b4615</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x3b9ae61b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x3b9add69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x3b9b3601</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x3b9b2599</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76717</th>\n",
       "      <td>0xb2d69017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76718</th>\n",
       "      <td>0xb2d68153</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76719</th>\n",
       "      <td>0xb2d5bba1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76720</th>\n",
       "      <td>0xb2d61b9b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76721</th>\n",
       "      <td>0xb2d70079</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76722 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          cust_no  label\n",
       "0      0x3b9b4615      0\n",
       "1      0x3b9ae61b      1\n",
       "2      0x3b9add69      1\n",
       "3      0x3b9b3601      0\n",
       "4      0x3b9b2599      1\n",
       "...           ...    ...\n",
       "76717  0xb2d69017      1\n",
       "76718  0xb2d68153      1\n",
       "76719  0xb2d5bba1      1\n",
       "76720  0xb2d61b9b      1\n",
       "76721  0xb2d70079      0\n",
       "\n",
       "[76722 rows x 2 columns]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_2 = pd.DataFrame(cnn_445['cust_no'])\n",
    "ensemble_2['label'] =  np.argmax((0.45*lgb_485[['prba1', 'prba2', 'prba3']].values + 0.3*xgb_1_prab[['prba1', 'prba2', 'prba3']].values  + 0.25*cnn_445[['pred_-1', 'pred_0', 'pred_1']].values), axis=1) - 1\n",
    "ensemble_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     73983\n",
       "False     2739\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lgb_485['label']==ensemble_2['label']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     75954\n",
       "False      768\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ensemble_1['label']==ensemble_2['label']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_2.to_csv('ensemble_2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "p_gZdEMJNq1m",
    "0aZ7FUbfNq1m"
   ],
   "name": "lgb8.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
